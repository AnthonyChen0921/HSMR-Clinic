{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# GAVD Video to HSMR Skeleton Parameters Pipeline\n",
    "\n",
    "This notebook processes GAVD videos using the HSMR model to extract skeleton parameters. The pipeline converts video files into `.npy` files containing skeletal motion data.\n",
    "\n",
    "## Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n",
      "üìÅ Input directory: ./GAVD-sequences\n",
      "üìÅ Cropped videos directory: ./GAVD-cropped-sequences\n",
      "üìÅ Output directory: ./GAVD-hsmr-params\n",
      "üé• Total videos found: 1801\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ast\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Add HSMR to path\n",
    "sys.path.append('./HSMR')\n",
    "\n",
    "# Configuration\n",
    "GAVD_SEQUENCES_DIR = \"./GAVD-sequences\"\n",
    "OUTPUT_DIR = \"./GAVD-hsmr-params\"\n",
    "HSMR_SCRIPT = \"./HSMR/exp/run_demo.py\"\n",
    "GAVD_DATA_DIR = \"./GAVD/data\"\n",
    "CROPPED_VIDEOS_DIR = \"./GAVD-cropped-sequences\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(CROPPED_VIDEOS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Setup complete!\")\n",
    "print(f\"üìÅ Input directory: {GAVD_SEQUENCES_DIR}\")\n",
    "print(f\"üìÅ Cropped videos directory: {CROPPED_VIDEOS_DIR}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"üé• Total videos found: {len(list(Path(GAVD_SEQUENCES_DIR).glob('*.mp4')))}\")\n",
    "\n",
    "# set $env:PYOPENGL_PLATFORM = \"pyglet\" for HSMR\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'pyglet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading GAVD dataset...\n",
      "  Loading GAVD_Clinical_Annotations_1.csv...\n",
      "    Shape: (91624, 10)\n",
      "  Loading GAVD_Clinical_Annotations_2.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1nkas-Strix-4090-ll\\AppData\\Local\\Temp\\ipykernel_33824\\1934443960.py:17: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_part = pd.read_csv(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Shape: (91623, 10)\n",
      "  Loading GAVD_Clinical_Annotations_3.csv...\n",
      "    Shape: (91623, 10)\n",
      "  Loading GAVD_Clinical_Annotations_4.csv...\n",
      "    Shape: (91623, 10)\n",
      "  Loading GAVD_Clinical_Annotations_5.csv...\n",
      "    Shape: (91623, 10)\n",
      "‚úÖ Complete dataset loaded: (458116, 10)\n",
      "üìº Total unique sequences: 1874\n",
      "üîß UPDATED function with bounding box cropping defined successfully!\n",
      "üìç Model path: ./HSMR/data_inputs/released_models/HSMR-ViTH-r1d1\n",
      "‚úÇÔ∏è Bounding box cropping: ENABLED\n"
     ]
    }
   ],
   "source": [
    "# Load GAVD dataset with bounding box information\n",
    "def load_gavd_dataset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the complete GAVD dataset from CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Complete dataset with bounding box information\n",
    "    \"\"\"\n",
    "    print(\"üìä Loading GAVD dataset...\")\n",
    "    all_dfs = []\n",
    "    \n",
    "    for i in range(1, 6):  # Parts 1-5\n",
    "        filename = f'GAVD_Clinical_Annotations_{i}.csv'\n",
    "        filepath = Path(GAVD_DATA_DIR) / filename\n",
    "        if filepath.exists():\n",
    "            print(f\"  Loading {filename}...\")\n",
    "            df_part = pd.read_csv(filepath)\n",
    "            all_dfs.append(df_part)\n",
    "            print(f\"    Shape: {df_part.shape}\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        df_complete = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(f\"‚úÖ Complete dataset loaded: {df_complete.shape}\")\n",
    "        print(f\"üìº Total unique sequences: {df_complete['seq'].nunique()}\")\n",
    "        return df_complete\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No GAVD CSV files found!\")\n",
    "\n",
    "def parse_bbox_string(bbox_str: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse bounding box string to dictionary.\n",
    "    \n",
    "    Args:\n",
    "        bbox_str (str): String representation of bounding box dict\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Parsed bounding box with keys: top, left, height, width\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(bbox_str) or bbox_str == 'nan':\n",
    "            return None\n",
    "        # Use ast.literal_eval to safely parse the string representation of dict\n",
    "        bbox_dict = ast.literal_eval(bbox_str)\n",
    "        return bbox_dict\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"‚ö†Ô∏è Error parsing bbox: {bbox_str} - {e}\")\n",
    "        return None\n",
    "\n",
    "def get_sequence_bbox_data(sequence_id: str, gavd_df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get bounding box data for a specific sequence.\n",
    "    \n",
    "    Args:\n",
    "        sequence_id (str): The sequence ID to lookup\n",
    "        gavd_df (pd.DataFrame): The GAVD dataset\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: Sequence data with bounding boxes, sorted by frame number\n",
    "    \"\"\"\n",
    "    sequence_data = gavd_df[gavd_df['seq'] == sequence_id].copy()\n",
    "    \n",
    "    if sequence_data.empty:\n",
    "        print(f\"‚ö†Ô∏è No bounding box data found for sequence: {sequence_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by frame number\n",
    "    sequence_data = sequence_data.sort_values('frame_num').reset_index(drop=True)\n",
    "    \n",
    "    # Parse bounding box strings\n",
    "    sequence_data['bbox_parsed'] = sequence_data['bbox'].apply(parse_bbox_string)\n",
    "    \n",
    "    return sequence_data\n",
    "\n",
    "def crop_video_with_bbox(input_video_path: str, output_video_path: str, \n",
    "                        sequence_data: pd.DataFrame, padding: int = 20) -> bool:\n",
    "    \"\"\"\n",
    "    Crop video using bounding box data from GAVD dataset.\n",
    "    \n",
    "    Args:\n",
    "        input_video_path (str): Path to input video\n",
    "        output_video_path (str): Path to save cropped video\n",
    "        sequence_data (pd.DataFrame): Sequence data with bounding boxes\n",
    "        padding (int): Extra padding around bounding box\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open input video\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {input_video_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"üé¨ Input video: {total_frames} frames at {fps} FPS\")\n",
    "        print(f\"üìã Sequence data: {len(sequence_data)} frames\")\n",
    "        \n",
    "        # Create frame number to bbox mapping\n",
    "        bbox_map = {}\n",
    "        for _, row in sequence_data.iterrows():\n",
    "            frame_num = row['frame_num']\n",
    "            bbox = row['bbox_parsed']\n",
    "            if bbox is not None:\n",
    "                bbox_map[frame_num] = bbox\n",
    "        \n",
    "        if not bbox_map:\n",
    "            print(\"‚ùå No valid bounding boxes found!\")\n",
    "            return False\n",
    "        \n",
    "        # Calculate consistent crop region from all bounding boxes\n",
    "        all_tops = [bbox['top'] for bbox in bbox_map.values()]\n",
    "        all_lefts = [bbox['left'] for bbox in bbox_map.values()]\n",
    "        all_bottoms = [bbox['top'] + bbox['height'] for bbox in bbox_map.values()]\n",
    "        all_rights = [bbox['left'] + bbox['width'] for bbox in bbox_map.values()]\n",
    "        \n",
    "        # Use the bounding box that encompasses all person positions\n",
    "        crop_top = max(0, int(min(all_tops)) - padding)\n",
    "        crop_left = max(0, int(min(all_lefts)) - padding)\n",
    "        crop_bottom = int(max(all_bottoms)) + padding\n",
    "        crop_right = int(max(all_rights)) + padding\n",
    "        \n",
    "        # Get video dimensions for validation\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        crop_bottom = min(crop_bottom, height)\n",
    "        crop_right = min(crop_right, width)\n",
    "        \n",
    "        crop_width = crop_right - crop_left\n",
    "        crop_height = crop_bottom - crop_top\n",
    "        \n",
    "        print(f\"üìê Crop region: ({crop_left}, {crop_top}) to ({crop_right}, {crop_bottom})\")\n",
    "        print(f\"üìè Crop size: {crop_width}x{crop_height}\")\n",
    "        \n",
    "        # Setup output video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (crop_width, crop_height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"‚ùå Cannot create output video: {output_video_path}\")\n",
    "            cap.release()\n",
    "            return False\n",
    "        \n",
    "        # FIXED: Handle frame number mismatch by processing ALL video frames\n",
    "        # The sequence frames from GAVD may not correspond directly to video frame indices\n",
    "        sequence_frames = set(sequence_data['frame_num'].values)\n",
    "        min_frame = min(sequence_frames)\n",
    "        max_frame = max(sequence_frames)\n",
    "        \n",
    "        print(f\"üéØ GAVD frame range: {min_frame} to {max_frame}\")\n",
    "        print(f\"üéØ Video frame range: 0 to {total_frames-1}\")\n",
    "        \n",
    "        # Since the frame numbers don't match video indices, process all video frames\n",
    "        # and use the bounding box information proportionally\n",
    "        frame_idx = 0\n",
    "        frames_written = 0\n",
    "        \n",
    "        # Create a sorted list of bounding boxes for interpolation\n",
    "        sorted_bboxes = [(row['frame_num'], row['bbox_parsed']) for _, row in sequence_data.iterrows() \n",
    "                        if row['bbox_parsed'] is not None]\n",
    "        sorted_bboxes.sort(key=lambda x: x[0])\n",
    "        \n",
    "        if not sorted_bboxes:\n",
    "            print(\"‚ùå No valid bounding boxes found after sorting!\")\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            return False\n",
    "        \n",
    "        print(f\"üì¶ Using {len(sorted_bboxes)} bounding boxes for cropping\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Use a consistent bounding box for all frames (could be improved with interpolation)\n",
    "            # For now, use the first valid bounding box\n",
    "            bbox = sorted_bboxes[0][1]  # Use first bbox\n",
    "            \n",
    "            # Dynamic crop based on current bbox (optional: interpolate between bboxes)\n",
    "            # For consistency, we'll use the pre-calculated crop region\n",
    "            cropped_frame = frame[crop_top:crop_bottom, crop_left:crop_right]\n",
    "            out.write(cropped_frame)\n",
    "            frames_written += 1\n",
    "            \n",
    "            frame_idx += 1\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"‚úÖ Cropped video saved: {frames_written} frames written\")\n",
    "        \n",
    "        # Verify output file\n",
    "        if frames_written == 0:\n",
    "            print(\"‚ö†Ô∏è Warning: No frames were written to output file!\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error cropping video: {e}\")\n",
    "        return False\n",
    "\n",
    "# UPDATED function with bounding box cropping\n",
    "def process_video_with_hsmr(video_path, output_dir, gavd_df=None, use_bbox_crop=True, \n",
    "                          verbose=True, show_output=True):\n",
    "    \"\"\"\n",
    "    Process a single video file using HSMR to extract skeleton parameters.\n",
    "    Optionally crops video using GAVD bounding box data first.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file\n",
    "        output_dir (str): Directory to save the output .npy file\n",
    "        gavd_df (pd.DataFrame): GAVD dataset with bounding box information\n",
    "        use_bbox_crop (bool): Whether to crop video using bounding box data\n",
    "        verbose (bool): Whether to print progress information\n",
    "        show_output (bool): Whether to show real-time command output\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success, output_file_path, error_message)\n",
    "    \"\"\"\n",
    "    video_path = Path(video_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    if not video_path.exists():\n",
    "        return False, None, f\"Video file not found: {video_path}\"\n",
    "    \n",
    "    # Expected output file name (HSMR adds the model name prefix)\n",
    "    expected_output = output_dir / f\"HSMR-{video_path.stem}.npy\"\n",
    "    \n",
    "    # Check if already processed\n",
    "    if expected_output.exists():\n",
    "        if verbose:\n",
    "            print(f\"‚è≠Ô∏è Skipping {video_path.name} - already processed\")\n",
    "        return True, expected_output, None\n",
    "    \n",
    "    # Determine which video file to process\n",
    "    video_to_process = video_path\n",
    "    \n",
    "    # Crop video using bounding box if requested and data is available\n",
    "    if use_bbox_crop and gavd_df is not None:\n",
    "        sequence_id = video_path.stem  # Extract sequence ID from filename\n",
    "        sequence_data = get_sequence_bbox_data(sequence_id, gavd_df)\n",
    "        \n",
    "        if sequence_data is not None:\n",
    "            # Create cropped video path\n",
    "            cropped_video_path = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_cropped.mp4\"\n",
    "            \n",
    "            if not cropped_video_path.exists():\n",
    "                if verbose:\n",
    "                    print(f\"‚úÇÔ∏è Cropping video using bounding box data...\")\n",
    "                \n",
    "                success = crop_video_with_bbox(\n",
    "                    str(video_path), \n",
    "                    str(cropped_video_path), \n",
    "                    sequence_data\n",
    "                )\n",
    "                \n",
    "                if not success:\n",
    "                    if verbose:\n",
    "                        print(f\"‚ö†Ô∏è Cropping failed, using original video\")\n",
    "                else:\n",
    "                    video_to_process = cropped_video_path\n",
    "                    if verbose:\n",
    "                        print(f\"‚úÖ Using cropped video: {cropped_video_path}\")\n",
    "            else:\n",
    "                video_to_process = cropped_video_path\n",
    "                if verbose:\n",
    "                    print(f\"üìÅ Using existing cropped video: {cropped_video_path}\")\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"‚ö†Ô∏è No bounding box data found for {sequence_id}, using original video\")\n",
    "    \n",
    "    try:\n",
    "        # Construct the command with CORRECT model path\n",
    "        model_root = \"./HSMR/data_inputs/released_models/HSMR-ViTH-r1d1\"\n",
    "        cmd = [\n",
    "            \"python\", \n",
    "            HSMR_SCRIPT,\n",
    "            \"--input_path\", str(video_to_process),\n",
    "            \"--output_path\", str(output_dir),\n",
    "            \"--model_root\", model_root\n",
    "        ]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"üé¨ Processing: {video_to_process.name}\")\n",
    "            print(f\"üíª Command: {' '.join(cmd)}\")\n",
    "            if show_output:\n",
    "                print(\"üì∫ Real-time output:\")\n",
    "                print(\"=\" * 80)\n",
    "        \n",
    "        # Run the command with real-time output\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if show_output and verbose:\n",
    "            # Show real-time output\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                bufsize=1,\n",
    "                universal_newlines=True,\n",
    "                cwd=\".\"\n",
    "            )\n",
    "            \n",
    "            # Print output in real-time\n",
    "            output_lines = []\n",
    "            for line in iter(process.stdout.readline, ''):\n",
    "                if line.strip():  # Only print non-empty lines\n",
    "                    print(f\"üìü {line.rstrip()}\")\n",
    "                output_lines.append(line)\n",
    "            \n",
    "            process.stdout.close()\n",
    "            return_code = process.wait()\n",
    "            \n",
    "            full_output = ''.join(output_lines)\n",
    "            \n",
    "        else:\n",
    "            # Capture output without showing (for batch processing)\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                cwd=\".\"\n",
    "            )\n",
    "            return_code = result.returncode\n",
    "            full_output = result.stdout\n",
    "            stderr_output = result.stderr\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        if return_code == 0:\n",
    "            if verbose:\n",
    "                if show_output:\n",
    "                    print(\"=\" * 80)\n",
    "                print(f\"‚úÖ Success! Processed in {end_time - start_time:.2f}s\")\n",
    "                print(f\"üìÑ Output: {expected_output}\")\n",
    "            return True, expected_output, None\n",
    "        else:\n",
    "            if show_output and verbose:\n",
    "                error_msg = f\"Command failed with return code {return_code}\\\\nOutput: {full_output}\"\n",
    "            else:\n",
    "                error_msg = f\"Command failed with return code {return_code}\\\\nSTDOUT: {full_output}\\\\nSTDERR: {stderr_output if 'stderr_output' in locals() else 'N/A'}\"\n",
    "            \n",
    "            if verbose:\n",
    "                if show_output:\n",
    "                    print(\"=\" * 80)\n",
    "                print(f\"‚ùå Failed: {error_msg}\")\n",
    "            return False, None, error_msg\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Exception occurred: {str(e)}\"\n",
    "        if verbose:\n",
    "            print(f\"‚ùå Exception: {error_msg}\")\n",
    "        return False, None, error_msg\n",
    "\n",
    "# Load the GAVD dataset\n",
    "try:\n",
    "    gavd_dataset = load_gavd_dataset()\n",
    "    print(\"üîß UPDATED function with bounding box cropping defined successfully!\")\n",
    "    print(\"üìç Model path: ./HSMR/data_inputs/released_models/HSMR-ViTH-r1d1\")\n",
    "    print(\"‚úÇÔ∏è Bounding box cropping: ENABLED\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not load GAVD dataset: {e}\")\n",
    "    print(\"üîß Function defined with bounding box cropping DISABLED\")\n",
    "    gavd_dataset = None\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Sample Processing\n",
    "\n",
    "Process a few sample videos to test the pipeline and verify everything works correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìº Found 1801 video files\n",
      "üéØ Selected 1 videos for sample processing:\n",
      "  1. cljanb45y00083n6lmh1qhydd.mp4 (0.5 MB)\n",
      "\\n==================================================\n",
      "üöÄ Starting sample processing...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all video files\n",
    "video_files = list(Path(GAVD_SEQUENCES_DIR).glob('*.mp4'))\n",
    "print(f\"üìº Found {len(video_files)} video files\")\n",
    "\n",
    "# Select first 3 videos for sample processing\n",
    "sample_videos = video_files[1:2]\n",
    "print(f\"üéØ Selected {len(sample_videos)} videos for sample processing:\")\n",
    "for i, video in enumerate(sample_videos, 1):\n",
    "    print(f\"  {i}. {video.name} ({video.stat().st_size / (1024*1024):.1f} MB)\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"üöÄ Starting sample processing...\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the FIXED cropping function\n",
    "# print(\"üîÑ Testing FIXED bounding box cropping (ignoring GAVD frame numbers)...\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Clean up any existing test files\n",
    "# test_sequence = \"cljanb45y00083n6lmh1qhydd\"\n",
    "# test_files = list(Path(CROPPED_VIDEOS_DIR).glob(f'{test_sequence}*'))\n",
    "# for test_file in test_files:\n",
    "#     test_file.unlink()\n",
    "#     print(f\"üóëÔ∏è Cleaned up: {test_file.name}\")\n",
    "\n",
    "# # Run the test\n",
    "# test_bbox_cropping(test_sequence)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Test Bounding Box Cropping\n",
    "\n",
    "Let's test the bounding box cropping functionality on a sample video to verify it's working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Cleaned up: cljanb45y00083n6lmh1qhydd_test_cropped.mp4\n",
      "üß™ Testing bounding box cropping for sequence: cljanb45y00083n6lmh1qhydd\n",
      "============================================================\n",
      "üìã Sequence Information:\n",
      "  üìº Sequence ID: cljanb45y00083n6lmh1qhydd\n",
      "  üìä GAVD frames: 215\n",
      "  üéØ GAVD frame range: 2532 - 2746\n",
      "  üé¨ Video frames: 214\n",
      "  ‚ö° Video FPS: 30\n",
      "  üö∂ Gait pattern: parkinsons\n",
      "  üì∑ Camera view: left side\n",
      "\\nüîç Frame Mapping Analysis:\n",
      "  üìä GAVD sequence length: 215 frames\n",
      "  üé¨ Video length: 214 frames\n",
      "  üìê Ratio: 1.00 (GAVD/Video)\n",
      "  ‚ö†Ô∏è GAVD frame range exceeds video length!\n",
      "  üí° Will process all 214 video frames with bounding box data\n",
      "\\nüìê Bounding Box Statistics:\n",
      "  ‚úÖ Valid bboxes: 215/215\n",
      "  üìè Width range: 247.0 - 291.0 (avg: 268.1)\n",
      "  üìê Height range: 485.0 - 504.0 (avg: 491.0)\n",
      "  üéØ Position X: 453.0 - 805.0\n",
      "  üéØ Position Y: 110.0 - 131.0\n",
      "\\nüì¶ Sample Bounding Boxes:\n",
      "  First frame: top=129.0, left=805.0, width=247.0, height=485.0\n",
      "  Last frame:  top=131.0, left=475.0, width=247.0, height=485.0\n",
      "\\n‚úÇÔ∏è Testing Video Cropping:\n",
      "  üì• Input: GAVD-sequences\\cljanb45y00083n6lmh1qhydd.mp4 (0.46 MB)\n",
      "üé¨ Input video: 214 frames at 30 FPS\n",
      "üìã Sequence data: 215 frames\n",
      "üìê Crop region: (433, 90) to (1072, 636)\n",
      "üìè Crop size: 639x546\n",
      "üéØ GAVD frame range: 2532 to 2746\n",
      "üéØ Video frame range: 0 to 213\n",
      "üì¶ Using 215 bounding boxes for cropping\n",
      "‚úÖ Cropped video saved: 214 frames written\n",
      "  üì§ Output: GAVD-cropped-sequences\\cljanb45y00083n6lmh1qhydd_test_cropped.mp4 (0.80 MB)\n",
      "  üìä Size reduction: -74.0% (ratio: 1.740)\n",
      "  ‚úÖ Cropping test SUCCESSFUL!\n",
      "  üìä Output video: 214 frames\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test bounding box cropping functionality with frame analysis\n",
    "def test_bbox_cropping(sequence_id=\"cljanb45y00083n6lmh1qhydd\"):\n",
    "    \"\"\"Test the bounding box cropping functionality on a specific sequence.\"\"\"\n",
    "    \n",
    "    if gavd_dataset is None:\n",
    "        print(\"‚ùå GAVD dataset not loaded. Cannot test bounding box cropping.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üß™ Testing bounding box cropping for sequence: {sequence_id}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get sequence data\n",
    "    sequence_data = get_sequence_bbox_data(sequence_id, gavd_dataset)\n",
    "    \n",
    "    if sequence_data is None:\n",
    "        print(f\"‚ùå No data found for sequence: {sequence_id}\")\n",
    "        return\n",
    "    \n",
    "    # Check video file\n",
    "    input_video = Path(GAVD_SEQUENCES_DIR) / f\"{sequence_id}.mp4\"\n",
    "    if not input_video.exists():\n",
    "        print(f\"‚ùå Input video not found: {input_video}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties for comparison\n",
    "    cap = cv2.VideoCapture(str(input_video))\n",
    "    if cap.isOpened():\n",
    "        video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"‚ùå Cannot open video for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Display sequence information\n",
    "    print(f\"üìã Sequence Information:\")\n",
    "    print(f\"  üìº Sequence ID: {sequence_id}\")\n",
    "    print(f\"  üìä GAVD frames: {len(sequence_data)}\")\n",
    "    print(f\"  üéØ GAVD frame range: {sequence_data['frame_num'].min()} - {sequence_data['frame_num'].max()}\")\n",
    "    print(f\"  üé¨ Video frames: {video_frames}\")\n",
    "    print(f\"  ‚ö° Video FPS: {video_fps}\")\n",
    "    \n",
    "    if 'gait_pat' in sequence_data.columns:\n",
    "        print(f\"  üö∂ Gait pattern: {sequence_data['gait_pat'].iloc[0]}\")\n",
    "    if 'cam_view' in sequence_data.columns:\n",
    "        print(f\"  üì∑ Camera view: {sequence_data['cam_view'].iloc[0]}\")\n",
    "    \n",
    "    # Frame mapping analysis\n",
    "    gavd_min = sequence_data['frame_num'].min()\n",
    "    gavd_max = sequence_data['frame_num'].max()\n",
    "    gavd_range = gavd_max - gavd_min + 1\n",
    "    \n",
    "    print(f\"\\\\nüîç Frame Mapping Analysis:\")\n",
    "    print(f\"  üìä GAVD sequence length: {gavd_range} frames\")\n",
    "    print(f\"  üé¨ Video length: {video_frames} frames\")\n",
    "    print(f\"  üìê Ratio: {gavd_range/video_frames:.2f} (GAVD/Video)\")\n",
    "    \n",
    "    if gavd_range > video_frames:\n",
    "        print(f\"  ‚ö†Ô∏è GAVD frame range exceeds video length!\")\n",
    "        print(f\"  üí° Will process all {video_frames} video frames with bounding box data\")\n",
    "    \n",
    "    # Display bounding box statistics\n",
    "    valid_bboxes = [bbox for bbox in sequence_data['bbox_parsed'] if bbox is not None]\n",
    "    \n",
    "    if valid_bboxes:\n",
    "        print(f\"\\\\nüìê Bounding Box Statistics:\")\n",
    "        print(f\"  ‚úÖ Valid bboxes: {len(valid_bboxes)}/{len(sequence_data)}\")\n",
    "        \n",
    "        all_tops = [bbox['top'] for bbox in valid_bboxes]\n",
    "        all_lefts = [bbox['left'] for bbox in valid_bboxes]\n",
    "        all_widths = [bbox['width'] for bbox in valid_bboxes]\n",
    "        all_heights = [bbox['height'] for bbox in valid_bboxes]\n",
    "        \n",
    "        print(f\"  üìè Width range: {min(all_widths):.1f} - {max(all_widths):.1f} (avg: {np.mean(all_widths):.1f})\")\n",
    "        print(f\"  üìê Height range: {min(all_heights):.1f} - {max(all_heights):.1f} (avg: {np.mean(all_heights):.1f})\")\n",
    "        print(f\"  üéØ Position X: {min(all_lefts):.1f} - {max(all_lefts):.1f}\")\n",
    "        print(f\"  üéØ Position Y: {min(all_tops):.1f} - {max(all_tops):.1f}\")\n",
    "        \n",
    "        # Show first and last bbox\n",
    "        print(f\"\\\\nüì¶ Sample Bounding Boxes:\")\n",
    "        first_bbox = valid_bboxes[0]\n",
    "        last_bbox = valid_bboxes[-1]\n",
    "        \n",
    "        print(f\"  First frame: top={first_bbox['top']}, left={first_bbox['left']}, \"\n",
    "              f\"width={first_bbox['width']}, height={first_bbox['height']}\")\n",
    "        print(f\"  Last frame:  top={last_bbox['top']}, left={last_bbox['left']}, \"\n",
    "              f\"width={last_bbox['width']}, height={last_bbox['height']}\")\n",
    "    else:\n",
    "        print(f\"‚ùå No valid bounding boxes found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\\\n‚úÇÔ∏è Testing Video Cropping:\")\n",
    "    print(f\"  üì• Input: {input_video} ({input_video.stat().st_size / (1024*1024):.2f} MB)\")\n",
    "    \n",
    "    # Clean up any existing test files\n",
    "    test_output = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_test_cropped.mp4\"\n",
    "    if test_output.exists():\n",
    "        test_output.unlink()\n",
    "        print(f\"  üóëÔ∏è Removed existing test file\")\n",
    "    \n",
    "    # Perform cropping\n",
    "    success = crop_video_with_bbox(str(input_video), str(test_output), sequence_data)\n",
    "    \n",
    "    if success and test_output.exists():\n",
    "        output_size_mb = test_output.stat().st_size / (1024*1024)\n",
    "        input_size_mb = input_video.stat().st_size / (1024*1024)\n",
    "        compression_ratio = output_size_mb / input_size_mb if input_size_mb > 0 else 0\n",
    "        \n",
    "        print(f\"  üì§ Output: {test_output} ({output_size_mb:.2f} MB)\")\n",
    "        print(f\"  üìä Size reduction: {(1-compression_ratio)*100:.1f}% (ratio: {compression_ratio:.3f})\")\n",
    "        \n",
    "        if output_size_mb > 0.01:  # Check if file has reasonable size\n",
    "            print(f\"  ‚úÖ Cropping test SUCCESSFUL!\")\n",
    "            \n",
    "            # Verify the output video can be opened\n",
    "            test_cap = cv2.VideoCapture(str(test_output))\n",
    "            if test_cap.isOpened():\n",
    "                test_frames = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                test_cap.release()\n",
    "                print(f\"  üìä Output video: {test_frames} frames\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Output video cannot be opened!\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Output file too small - cropping may have failed!\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"  ‚ùå Cropping test FAILED!\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Clean up any existing test files first\n",
    "existing_test_files = list(Path(CROPPED_VIDEOS_DIR).glob('*test_cropped.mp4'))\n",
    "for test_file in existing_test_files:\n",
    "    test_file.unlink()\n",
    "    print(f\"üóëÔ∏è Cleaned up: {test_file.name}\")\n",
    "\n",
    "# Run the test\n",
    "test_bbox_cropping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process sample videos with FIXED bounding box cropping\n",
    "# print(\"üöÄ Running sample processing with FIXED cropping...\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# sample_results = []\n",
    "\n",
    "# for i, video_path in enumerate(sample_videos, 1):\n",
    "#     print(f\"\\\\nüìπ Processing sample {i}/{len(sample_videos)}: {video_path.name}\")\n",
    "#     print(\"-\" * 60)\n",
    "    \n",
    "#     # Check if we have bounding box data for this sequence\n",
    "#     sequence_id = video_path.stem\n",
    "#     if gavd_dataset is not None:\n",
    "#         sequence_data = get_sequence_bbox_data(sequence_id, gavd_dataset)\n",
    "#         if sequence_data is not None:\n",
    "#             print(f\"üìã Found {len(sequence_data)} bounding box annotations\")\n",
    "#             print(f\"üìä GAVD frame range: {sequence_data['frame_num'].min()} - {sequence_data['frame_num'].max()}\")\n",
    "#             print(f\"üí° Will ignore frame numbers and use bbox data for consistent cropping\")\n",
    "            \n",
    "#             # Show sample bounding box\n",
    "#             sample_bbox = sequence_data.iloc[0]['bbox_parsed']\n",
    "#             if sample_bbox:\n",
    "#                 print(f\"üìê Sample bbox: top={sample_bbox['top']}, left={sample_bbox['left']}, \"\n",
    "#                       f\"width={sample_bbox['width']}, height={sample_bbox['height']}\")\n",
    "#         else:\n",
    "#             print(\"‚ö†Ô∏è No bounding box data found for this sequence\")\n",
    "    \n",
    "#     # Clean any existing cropped video for this sequence to force re-cropping\n",
    "#     cropped_path = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_cropped.mp4\"\n",
    "#     if cropped_path.exists():\n",
    "#         cropped_path.unlink()\n",
    "#         print(f\"üóëÔ∏è Removed existing cropped video to test new cropping\")\n",
    "    \n",
    "#     success, output_path, error = process_video_with_hsmr(\n",
    "#         video_path=video_path,\n",
    "#         output_dir=OUTPUT_DIR,\n",
    "#         gavd_df=gavd_dataset,  # Pass the GAVD dataset\n",
    "#         use_bbox_crop=True,    # Enable bounding box cropping\n",
    "#         verbose=True,\n",
    "#         show_output=True  # Don't show HSMR output for cleaner test\n",
    "#     )\n",
    "    \n",
    "#     sample_results.append({\n",
    "#         'video': video_path.name,\n",
    "#         'success': success,\n",
    "#         'output': output_path,\n",
    "#         'error': error\n",
    "#     })\n",
    "    \n",
    "#     if success:\n",
    "#         print(f\"‚úÖ Sample {i} completed successfully!\")\n",
    "#         if output_path and output_path.exists():\n",
    "#             print(f\"üìä Output file size: {output_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "#     else:\n",
    "#         print(f\"‚ùå Sample {i} failed: {error}\")\n",
    "    \n",
    "#     print(\"-\" * 60)\n",
    "\n",
    "# # Summary\n",
    "# print(f\"\\\\nüìã Sample Processing Summary:\")\n",
    "# print(f\"‚úÖ Successful: {sum(1 for r in sample_results if r['success'])}\")\n",
    "# print(f\"‚ùå Failed: {sum(1 for r in sample_results if not r['success'])}\")\n",
    "\n",
    "# for result in sample_results:\n",
    "#     status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
    "#     print(f\"  {status} {result['video']}\")\n",
    "#     if not result['success']:\n",
    "#         print(f\"    Error: {result['error'][:100]}...\")  # Truncate long errors\n",
    "\n",
    "# # Show cropped videos info with detailed analysis\n",
    "# cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "# if cropped_videos:\n",
    "#     print(f\"\\\\n‚úÇÔ∏è Generated {len(cropped_videos)} cropped videos:\")\n",
    "#     for cropped_video in cropped_videos:\n",
    "#         size_mb = cropped_video.stat().st_size / (1024*1024)\n",
    "#         print(f\"  üìÑ {cropped_video.name} ({size_mb:.2f} MB)\")\n",
    "        \n",
    "#         # Verify the cropped video can be opened\n",
    "#         try:\n",
    "#             test_cap = cv2.VideoCapture(str(cropped_video))\n",
    "#             if test_cap.isOpened():\n",
    "#                 frames = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#                 width = int(test_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#                 height = int(test_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#                 test_cap.release()\n",
    "#                 print(f\"    ‚úÖ Playable: {frames} frames, {width}x{height}\")\n",
    "#             else:\n",
    "#                 print(f\"    ‚ùå Cannot open video file\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"    ‚ùå Error checking video: {e}\")\n",
    "\n",
    "# print(\"\\\\nüéâ FIXED cropping test complete!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process all videos in the GAVD-sequences directory. This cell will process all remaining videos with progress tracking and error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Batch processing function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import gc  # For garbage collection\n",
    "\n",
    "# Skip list management\n",
    "SKIP_LIST_FILE = \"failed_videos_skiplist.txt\"\n",
    "\n",
    "def load_skip_list():\n",
    "    \"\"\"Load the list of videos to skip from file.\"\"\"\n",
    "    skip_list = set()\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    if skip_file.exists():\n",
    "        with open(skip_file, 'r') as f:\n",
    "            skip_list = set(line.strip() for line in f if line.strip())\n",
    "        print(f\"üìã Loaded skip list: {len(skip_list)} videos to skip\")\n",
    "    return skip_list\n",
    "\n",
    "def add_to_skip_list(video_name, error_msg):\n",
    "    \"\"\"Add a video to the skip list.\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    with open(skip_file, 'a') as f:\n",
    "        f.write(f\"{video_name}\\n\")\n",
    "    \n",
    "    # Also log the detailed error\n",
    "    error_log_file = Path(\"failed_videos_errors.log\")\n",
    "    with open(error_log_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"\\n{'='*80}\\n\")\n",
    "        f.write(f\"Video: {video_name}\\n\")\n",
    "        f.write(f\"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Error: {error_msg}\\n\")\n",
    "        f.write(f\"{'='*80}\\n\")\n",
    "\n",
    "def batch_process_videos(video_dir, output_dir, max_videos=None, skip_existing=True, \n",
    "                        use_bbox_crop=True, gavd_df=None, auto_skip_failed=True):\n",
    "    \"\"\"\n",
    "    Batch process all videos in a directory with optional bounding box cropping.\n",
    "    \n",
    "    Args:\n",
    "        video_dir (str): Directory containing input videos\n",
    "        output_dir (str): Directory to save output files\n",
    "        max_videos (int, optional): Maximum number of videos to process (for testing)\n",
    "        skip_existing (bool): Whether to skip already processed videos\n",
    "        use_bbox_crop (bool): Whether to use bounding box cropping\n",
    "        gavd_df (pd.DataFrame): GAVD dataset with bounding box information\n",
    "        auto_skip_failed (bool): Whether to automatically skip previously failed videos\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processing statistics and results\n",
    "    \"\"\"\n",
    "    video_files = list(Path(video_dir).glob('*.mp4'))\n",
    "    \n",
    "    # Load skip list\n",
    "    skip_list = load_skip_list() if auto_skip_failed else set()\n",
    "    \n",
    "    # Filter out videos in skip list\n",
    "    if skip_list:\n",
    "        original_count = len(video_files)\n",
    "        video_files = [v for v in video_files if v.name not in skip_list]\n",
    "        skipped_count = original_count - len(video_files)\n",
    "        print(f\"‚è≠Ô∏è Skipping {skipped_count} videos from previous failures\")\n",
    "    \n",
    "    if max_videos:\n",
    "        video_files = video_files[:max_videos]\n",
    "    \n",
    "    print(f\"üé¨ Starting batch processing of {len(video_files)} videos\")\n",
    "    print(f\"üìÅ Input: {video_dir}\")\n",
    "    print(f\"üìÅ Output: {output_dir}\")\n",
    "    print(f\"‚è≠Ô∏è Skip existing: {skip_existing}\")\n",
    "    print(f\"‚ö†Ô∏è Auto-skip failed: {auto_skip_failed}\")\n",
    "    print(f\"‚úÇÔ∏è Bounding box cropping: {'ENABLED' if use_bbox_crop and gavd_df is not None else 'DISABLED'}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process with progress bar\n",
    "    for i, video_path in enumerate(tqdm(video_files, desc=\"Processing videos\"), 1):\n",
    "        try:\n",
    "            success, output_path, error = process_video_with_hsmr(\n",
    "                video_path=video_path,\n",
    "                output_dir=output_dir,\n",
    "                gavd_df=gavd_df,  # Pass GAVD dataset\n",
    "                use_bbox_crop=use_bbox_crop,  # Enable/disable bbox cropping\n",
    "                verbose=False,  # Reduce verbosity for batch processing\n",
    "                show_output=True  # Don't show output for batch processing\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'video': video_path.name,\n",
    "                'success': success,\n",
    "                'output': output_path,\n",
    "                'error': error,\n",
    "                'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "            \n",
    "            # Handle failed videos\n",
    "            if not success:\n",
    "                # Show full error message\n",
    "                print(f\"\\n‚ùå [{i:4d}/{len(video_files):4d}] {video_path.name}\")\n",
    "                print(f\"üìÑ FULL ERROR MESSAGE:\")\n",
    "                print(\"=\" * 60)\n",
    "                print(error)\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                # Add to skip list for future runs\n",
    "                add_to_skip_list(video_path.name, error)\n",
    "                print(f\"üìù Added {video_path.name} to skip list\")\n",
    "            \n",
    "            # Print periodic success updates\n",
    "            elif i % 10 == 0:\n",
    "                print(f\"‚úÖ [{i:4d}/{len(video_files):4d}] {video_path.name}\")\n",
    "            \n",
    "            # Garbage collection every 20 videos to prevent memory buildup\n",
    "            if i % 20 == 0:\n",
    "                gc.collect()\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected exception during processing: {str(e)}\"\n",
    "            print(f\"\\nüí• [{i:4d}/{len(video_files):4d}] {video_path.name}\")\n",
    "            print(f\"üìÑ EXCEPTION:\")\n",
    "            print(\"=\" * 60)\n",
    "            print(error_msg)\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            results.append({\n",
    "                'video': video_path.name,\n",
    "                'success': False,\n",
    "                'output': None,\n",
    "                'error': error_msg,\n",
    "                'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "            \n",
    "            # Add to skip list\n",
    "            add_to_skip_list(video_path.name, error_msg)\n",
    "            print(f\"üìù Added {video_path.name} to skip list\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = len(results) - successful\n",
    "    total_size_mb = sum(r['size_mb'] for r in results)\n",
    "    avg_time_per_video = total_time / len(results) if results else 0\n",
    "    \n",
    "    # Count cropped videos\n",
    "    cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "    \n",
    "    # Final garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    stats = {\n",
    "        'total_videos': len(results),\n",
    "        'successful': successful,\n",
    "        'failed': failed,\n",
    "        'total_time_seconds': total_time,\n",
    "        'avg_time_per_video': avg_time_per_video,\n",
    "        'total_size_mb': total_size_mb,\n",
    "        'cropped_videos': len(cropped_videos),\n",
    "        'skipped_from_list': len(skip_list) if skip_list else 0,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Test function definition\n",
    "print(\"üîß Batch processing function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Skip List Status:\n",
      "==================================================\n",
      "üìã Loaded skip list: 82 videos to skip\n",
      "üìÑ Skip list file: failed_videos_skiplist.txt\n",
      "üö´ Videos to skip: 82\n",
      "üìù Recent entries (last 10):\n",
      "  - cljap5o8u004r3n6llsoy3aww.mp4\n",
      "  - cljapao5600503n6lhrbr4zii.mp4\n",
      "  - cljapbtwe00543n6lsdbwbhhi.mp4\n",
      "  - cljaotzi6002g3n6ljofm5j6d.mp4\n",
      "  - cljaouueo002k3n6l57zl7081.mp4\n",
      "  - cljaqc7jf00943n6l9cmdtsmn.mp4\n",
      "  - cljaqdekt00983n6ldn9m222j.mp4\n",
      "  - cljaqocwq00a23n6lj8kgw100.mp4\n",
      "  - cljaqqdar00aa3n6lblt5iei7.mp4\n",
      "  - cljaqrnsq00ae3n6lo53132n5.mp4\n",
      "\n",
      "üìÑ Error log file: failed_videos_errors.log (0.38 MB)\n",
      "üí° Check this file for detailed error messages\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Skip List Management Utilities\n",
    "def show_skip_list_status():\n",
    "    \"\"\"Show current skip list status and recent failures.\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    error_log_file = Path(\"failed_videos_errors.log\")\n",
    "    \n",
    "    print(\"üìã Skip List Status:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if skip_file.exists():\n",
    "        skip_list = load_skip_list()\n",
    "        print(f\"üìÑ Skip list file: {SKIP_LIST_FILE}\")\n",
    "        print(f\"üö´ Videos to skip: {len(skip_list)}\")\n",
    "        \n",
    "        if len(skip_list) > 0:\n",
    "            print(f\"üìù Recent entries (last 10):\")\n",
    "            with open(skip_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines[-10:]:\n",
    "                    print(f\"  - {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"üìÑ No skip list found ({SKIP_LIST_FILE})\")\n",
    "    \n",
    "    print()\n",
    "    if error_log_file.exists():\n",
    "        size_mb = error_log_file.stat().st_size / (1024*1024)\n",
    "        print(f\"üìÑ Error log file: failed_videos_errors.log ({size_mb:.2f} MB)\")\n",
    "        print(f\"üí° Check this file for detailed error messages\")\n",
    "    else:\n",
    "        print(f\"üìÑ No error log found\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def clear_skip_list():\n",
    "    \"\"\"Clear the skip list (use with caution!).\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    if skip_file.exists():\n",
    "        skip_file.unlink()\n",
    "        print(f\"üóëÔ∏è Cleared skip list: {SKIP_LIST_FILE}\")\n",
    "    else:\n",
    "        print(f\"üìÑ No skip list to clear\")\n",
    "\n",
    "def remove_from_skip_list(video_names):\n",
    "    \"\"\"Remove specific videos from skip list.\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    if not skip_file.exists():\n",
    "        print(f\"üìÑ No skip list found\")\n",
    "        return\n",
    "    \n",
    "    # Read current skip list\n",
    "    with open(skip_file, 'r') as f:\n",
    "        current_list = set(line.strip() for line in f if line.strip())\n",
    "    \n",
    "    # Remove specified videos\n",
    "    if isinstance(video_names, str):\n",
    "        video_names = [video_names]\n",
    "    \n",
    "    removed_count = 0\n",
    "    for video_name in video_names:\n",
    "        if video_name in current_list:\n",
    "            current_list.remove(video_name)\n",
    "            removed_count += 1\n",
    "            print(f\"‚úÖ Removed {video_name} from skip list\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {video_name} not found in skip list\")\n",
    "    \n",
    "    # Write back the updated list\n",
    "    if removed_count > 0:\n",
    "        with open(skip_file, 'w') as f:\n",
    "            for video_name in sorted(current_list):\n",
    "                f.write(f\"{video_name}\\n\")\n",
    "        print(f\"üìù Updated skip list: removed {removed_count} videos\")\n",
    "\n",
    "# Show current status\n",
    "show_skip_list_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Loaded skip list: 82 videos to skip\n",
      "‚è≠Ô∏è Skipping 82 videos from previous failures\n",
      "üé¨ Starting batch processing of 1719 videos\n",
      "üìÅ Input: ./GAVD-sequences\n",
      "üìÅ Output: ./GAVD-hsmr-params\n",
      "‚è≠Ô∏è Skip existing: True\n",
      "‚ö†Ô∏è Auto-skip failed: True\n",
      "‚úÇÔ∏è Bounding box cropping: ENABLED\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 1/1719 [02:50<81:30:38, 170.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå [   1/1719] cljaoyz1c003c3n6l84cbjwg9.mp4\n",
      "üìÑ FULL ERROR MESSAGE:\n",
      "============================================================\n",
      "Command failed with return code 3221225477\\nSTDOUT: Found GAVD-cropped-sequences\\cljaoyz1c003c3n6l84cbjwg9_cropped.mp4 is a file. It will be regarded as a video file.\n",
      "\\nSTDERR: [\u001b[36m07/28 13:40:27\u001b[0m][\u001b[32mINFO\u001b[0m] üöö Loading inputs from: GAVD-cropped-sequences\\cljaoyz1c003c3n6l84cbjwg9_cropped.mp4, regarded as <video>.\u001b[0m\n",
      "\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [00:00<00:00, 3961.57it/s]\n",
      "[\u001b[36m07/28 13:40:27\u001b[0m][\u001b[32mINFO\u001b[0m] üì¶ Totally 111 images are loaded.\u001b[0m\n",
      "[\u001b[36m07/28 13:40:27\u001b[0m][\u001b[32mINFO\u001b[0m] üß± Building detector.\u001b[0m\n",
      "c:\\Users\\1nkas-Strix-4090-ll\\miniconda3\\envs\\hsmr\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "[\u001b[36m07/28 13:40:30\u001b[0m][\u001b[32mINFO\u001b[0m] [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692/model_final_f05665.pkl ...\u001b[0m\n",
      "[\u001b[36m07/28 13:40:30\u001b[0m][\u001b[32mINFO\u001b[0m] URL https://dl.fbaipublicfiles.com/detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692/model_final_f05665.pkl cached in C:\\Users\\1nkas-Strix-4090-ll/.torch/iopath_cache\\detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692\\model_final_f05665.pkl\u001b[0m\n",
      "[\u001b[36m07/28 13:40:30\u001b[0m][\u001b[32mINFO\u001b[0m] [Checkpointer] Loading from C:\\Users\\1nkas-Strix-4090-ll/.torch/iopath_cache\\detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692\\model_final_f05665.pkl ...\u001b[0m\n",
      "[\u001b[36m07/28 13:40:31\u001b[0m][\u001b[32mINFO\u001b[0m] Reading a file from 'Detectron2 ViTDet Model Zoo'\u001b[0m\n",
      "[\u001b[36m07/28 13:40:31\u001b[0m][\u001b[32mINFO\u001b[0m] [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=1024)]\u001b[0m\n",
      "[\u001b[36m07/28 13:40:31\u001b[0m][\u001b[32mINFO\u001b[0m] üñºÔ∏è Detecting...\u001b[0m\n",
      "\n",
      "Batch Detection:   0%|          | 0/111 [00:00<?, ?it/s]c:\\Users\\1nkas-Strix-4090-ll\\miniconda3\\envs\\hsmr\\lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "Batch Detection:   9%|‚ñâ         | 10/111 [00:15<02:39,  1.58s/it]\n",
      "Batch Detection:  18%|‚ñà‚ñä        | 20/111 [00:30<02:17,  1.51s/it]\n",
      "Batch Detection:  27%|‚ñà‚ñà‚ñã       | 30/111 [00:44<01:59,  1.48s/it]\n",
      "Batch Detection:  36%|‚ñà‚ñà‚ñà‚ñå      | 40/111 [00:59<01:43,  1.46s/it]\n",
      "Batch Detection:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 50/111 [01:13<01:28,  1.45s/it]\n",
      "Batch Detection:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 60/111 [01:27<01:13,  1.44s/it]\n",
      "Batch Detection:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 70/111 [01:42<00:59,  1.44s/it]\n",
      "Batch Detection:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 80/111 [01:56<00:44,  1.44s/it]\n",
      "Batch Detection:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 90/111 [02:10<00:30,  1.44s/it]\n",
      "Batch Detection:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 100/111 [02:25<00:15,  1.43s/it]\n",
      "Batch Detection:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 110/111 [02:39<00:01,  1.43s/it]\n",
      "Batch Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [02:39<00:00,  1.39s/it]\n",
      "Batch Detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [02:39<00:00,  1.44s/it]\n",
      "\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 111/111 [00:00<00:00, 1463.34it/s]\n",
      "[\u001b[36m07/28 13:43:12\u001b[0m][\u001b[32mINFO\u001b[0m] üîç Totally 111 human instances are detected.\u001b[0m\n",
      "[\u001b[36m07/28 13:43:12\u001b[0m][\u001b[32mINFO\u001b[0m] üß± Building recovery pipeline.\u001b[0m\n",
      "\n",
      "============================================================\n",
      "üìù Added cljaoyz1c003c3n6l84cbjwg9.mp4 to skip list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 8/1719 [42:34<274:44:35, 578.07s/it]"
     ]
    }
   ],
   "source": [
    "# Run batch processing with bounding box cropping\n",
    "# WARNING: This will process ALL videos in GAVD-sequences directory\n",
    "# Set max_videos to a small number for testing, or None to process all\n",
    "\n",
    "# For testing: process only 10 videos with bounding box cropping\n",
    "# batch_stats = batch_process_videos(GAVD_SEQUENCES_DIR, OUTPUT_DIR, max_videos=10, \n",
    "#                                  use_bbox_crop=True, gavd_df=gavd_dataset)\n",
    "\n",
    "# For full processing: remove max_videos parameter or set to None\n",
    "batch_stats = batch_process_videos(GAVD_SEQUENCES_DIR, OUTPUT_DIR, max_videos=None,\n",
    "                                 use_bbox_crop=True, gavd_df=gavd_dataset, \n",
    "                                 auto_skip_failed=True)  # Enable auto-skip of failed videos\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"üìä BATCH PROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìº Total videos processed: {batch_stats['total_videos']}\")\n",
    "print(f\"‚úÖ Successful: {batch_stats['successful']}\")\n",
    "print(f\"‚ùå Failed: {batch_stats['failed']}\")\n",
    "print(f\"‚è≠Ô∏è Skipped from skip list: {batch_stats.get('skipped_from_list', 0)}\")\n",
    "print(f\"‚úÇÔ∏è Cropped videos generated: {batch_stats.get('cropped_videos', 0)}\")\n",
    "print(f\"‚è±Ô∏è Total time: {batch_stats['total_time_seconds']:.2f} seconds ({batch_stats['total_time_seconds']/60:.1f} minutes)\")\n",
    "print(f\"‚ö° Average time per video: {batch_stats['avg_time_per_video']:.2f} seconds\")\n",
    "print(f\"üíæ Total input size: {batch_stats['total_size_mb']:.1f} MB\")\n",
    "\n",
    "if batch_stats['failed'] > 0:\n",
    "    print(f\"\\\\n‚ùå Failed videos:\")\n",
    "    failed_videos = [r for r in batch_stats['results'] if not r['success']]\n",
    "    for failed in failed_videos[:10]:  # Show first 10 failures\n",
    "        print(f\"  - {failed['video']}: {failed['error'][:80]}...\")\n",
    "    if len(failed_videos) > 10:\n",
    "        print(f\"  ... and {len(failed_videos) - 10} more failures\")\n",
    "\n",
    "print(f\"\\\\nüìÅ Output files saved to: {OUTPUT_DIR}\")\n",
    "output_files = list(Path(OUTPUT_DIR).glob('*.npy'))\n",
    "print(f\"üìÑ Generated {len(output_files)} .npy files\")\n",
    "\n",
    "print(f\"\\\\nüìÅ Cropped videos saved to: {CROPPED_VIDEOS_DIR}\")\n",
    "cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "if cropped_videos:\n",
    "    total_cropped_size = sum(v.stat().st_size for v in cropped_videos) / (1024*1024)\n",
    "    print(f\"‚úÇÔ∏è Generated {len(cropped_videos)} cropped videos ({total_cropped_size:.1f} MB total)\")\n",
    "else:\n",
    "    print(\"‚úÇÔ∏è No cropped videos generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Inspection\n",
    "\n",
    "Inspect the generated skeleton parameter files to understand the data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Inspecting: HSMR-cljan9b4p00043n6ligceanyp.npy\n",
      "üìä File size: 0.19 MB\n",
      "\\nüìã Data structure:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (511,)\n",
      "  Dtype: object\n",
      "\\nüé¨ Video has 511 frames\n",
      "\\nüì¶ First frame keys: ['patch_cam_t', 'poses', 'betas', 'bbx_cs']\n",
      "  patch_cam_t: shape=(1, 3), dtype=float32\n",
      "  poses: shape=(1, 46), dtype=float32\n",
      "  betas: shape=(1, 10), dtype=float32\n",
      "  bbx_cs: <class 'list'> - [array([268.77588, 372.10785, 497.57043], dtype=float32)]\n",
      "\\nü§∏ Pose parameters:\n",
      "  Shape: (1, 46)\n",
      "  Min/Max: -1.031 / 2.851\n",
      "  Mean: 0.119\n",
      "\\nüë§ Shape parameters (betas):\n",
      "  Shape: (1, 10)\n",
      "  Min/Max: -0.093 / 0.210\n",
      "\\nüì∑ Camera translation:\n",
      "  Shape: (1, 3)\n",
      "  Values: [[-0.07694656  0.06684598 32.80605   ]]\n",
      "\\n‚úÖ Successfully inspected HSMR-cljan9b4p00043n6ligceanyp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find and inspect a sample output file\n",
    "output_files = list(Path(OUTPUT_DIR).glob('*.npy'))\n",
    "\n",
    "if output_files:\n",
    "    # Load the first available output file\n",
    "    sample_file = output_files[0]\n",
    "    print(f\"üîç Inspecting: {sample_file.name}\")\n",
    "    print(f\"üìä File size: {sample_file.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Load the data\n",
    "        data = np.load(sample_file, allow_pickle=True)\n",
    "        print(f\"\\\\nüìã Data structure:\")\n",
    "        print(f\"  Type: {type(data)}\")\n",
    "        \n",
    "        if isinstance(data, np.ndarray):\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dtype: {data.dtype}\")\n",
    "            \n",
    "            # If it's an array of dictionaries (typical HSMR output)\n",
    "            if data.dtype == object and len(data) > 0:\n",
    "                print(f\"\\\\nüé¨ Video has {len(data)} frames\")\n",
    "                \n",
    "                # Inspect first frame\n",
    "                first_frame = data[0]\n",
    "                if isinstance(first_frame, dict):\n",
    "                    print(f\"\\\\nüì¶ First frame keys: {list(first_frame.keys())}\")\n",
    "                    \n",
    "                    for key, value in first_frame.items():\n",
    "                        if isinstance(value, np.ndarray):\n",
    "                            print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "                        else:\n",
    "                            print(f\"  {key}: {type(value)} - {value}\")\n",
    "                    \n",
    "                    # Show some specific parameter details\n",
    "                    if 'poses' in first_frame:\n",
    "                        poses = first_frame['poses']\n",
    "                        print(f\"\\\\nü§∏ Pose parameters:\")\n",
    "                        print(f\"  Shape: {poses.shape}\")\n",
    "                        print(f\"  Min/Max: {poses.min():.3f} / {poses.max():.3f}\")\n",
    "                        print(f\"  Mean: {poses.mean():.3f}\")\n",
    "                    \n",
    "                    if 'betas' in first_frame:\n",
    "                        betas = first_frame['betas']\n",
    "                        print(f\"\\\\nüë§ Shape parameters (betas):\")\n",
    "                        print(f\"  Shape: {betas.shape}\")\n",
    "                        print(f\"  Min/Max: {betas.min():.3f} / {betas.max():.3f}\")\n",
    "                    \n",
    "                    if 'patch_cam_t' in first_frame:\n",
    "                        cam_t = first_frame['patch_cam_t']\n",
    "                        print(f\"\\\\nüì∑ Camera translation:\")\n",
    "                        print(f\"  Shape: {cam_t.shape}\")\n",
    "                        print(f\"  Values: {cam_t}\")\n",
    "        \n",
    "        print(f\"\\\\n‚úÖ Successfully inspected {sample_file.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No output files found. Run the processing cells first.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Batch Video Cropping Only\n",
    "\n",
    "Generate cropped videos for all sequences using bounding box data without running HSMR processing. This is useful for pre-processing all videos or creating a cropped dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Per-frame dynamic cropping function defined successfully!\n",
      "‚úÇÔ∏è Uses exact per-frame bbox data from GAVD dataset\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED: Per-frame dynamic cropping function using GAVD bbox data\n",
    "def crop_video_with_bbox_per_frame(input_video_path: str, output_video_path: str, \n",
    "                                  sequence_data: pd.DataFrame, padding: int = 20, \n",
    "                                  show_frame_details: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Crop video using per-frame bounding box data from GAVD dataset.\n",
    "    Each frame uses its corresponding bounding box for cropping.\n",
    "    \n",
    "    Args:\n",
    "        input_video_path (str): Path to input video\n",
    "        output_video_path (str): Path to save cropped video\n",
    "        sequence_data (pd.DataFrame): Sequence data with bounding boxes\n",
    "        padding (int): Extra padding around bounding box\n",
    "        show_frame_details (bool): Whether to show frame-by-frame details\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open input video\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {input_video_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        print(f\"üé¨ Input video: {total_frames} frames at {fps} FPS ({width}x{height})\")\n",
    "        print(f\"üìã Sequence data: {len(sequence_data)} frames\")\n",
    "        \n",
    "        # Create sorted list of bounding boxes by frame number\n",
    "        valid_bboxes = []\n",
    "        for _, row in sequence_data.iterrows():\n",
    "            frame_num = row['frame_num']\n",
    "            bbox = row['bbox_parsed']\n",
    "            if bbox is not None:\n",
    "                valid_bboxes.append({\n",
    "                    'frame_num': frame_num,\n",
    "                    'bbox': bbox\n",
    "                })\n",
    "        \n",
    "        if not valid_bboxes:\n",
    "            print(\"‚ùå No valid bounding boxes found!\")\n",
    "            return False\n",
    "        \n",
    "        # Sort by frame number\n",
    "        valid_bboxes = sorted(valid_bboxes, key=lambda x: x['frame_num'])\n",
    "        \n",
    "        print(f\"üì¶ Found {len(valid_bboxes)} valid bounding boxes\")\n",
    "        \n",
    "        # Get GAVD frame range\n",
    "        min_gavd_frame = valid_bboxes[0]['frame_num']\n",
    "        max_gavd_frame = valid_bboxes[-1]['frame_num']\n",
    "        gavd_frame_range = max_gavd_frame - min_gavd_frame + 1\n",
    "        \n",
    "        print(f\"üéØ GAVD frame range: {min_gavd_frame} to {max_gavd_frame} ({gavd_frame_range} frames)\")\n",
    "        print(f\"üéØ Video frame range: 0 to {total_frames-1} ({total_frames} frames)\")\n",
    "        print(\"‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\")\n",
    "        \n",
    "        # Calculate maximum dimensions for consistent output size\n",
    "        all_bboxes = [item['bbox'] for item in valid_bboxes]\n",
    "        max_width = max(bbox['width'] for bbox in all_bboxes) + 2 * padding\n",
    "        max_height = max(bbox['height'] for bbox in all_bboxes) + 2 * padding\n",
    "        \n",
    "        # Ensure dimensions don't exceed original video\n",
    "        output_width = min(int(max_width), width)\n",
    "        output_height = min(int(max_height), height)\n",
    "        \n",
    "        print(f\"üìè Output video size: {output_width}x{output_height} (max bbox + padding)\")\n",
    "        \n",
    "        # Setup output video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (output_width, output_height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"‚ùå Cannot create output video: {output_video_path}\")\n",
    "            cap.release()\n",
    "            return False\n",
    "        \n",
    "        frames_written = 0\n",
    "        \n",
    "        if show_frame_details:\n",
    "            print(f\"\\nüìã FRAME-BY-FRAME DETAILS:\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        # Process each video frame with corresponding bbox\n",
    "        for video_frame_idx in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Map video frame index to GAVD data\n",
    "            # Since GAVD frames might not start from 0, we need to interpolate\n",
    "            if len(valid_bboxes) == total_frames:\n",
    "                # Direct 1:1 mapping\n",
    "                bbox_data = valid_bboxes[video_frame_idx]\n",
    "            else:\n",
    "                # Interpolate based on progress through video\n",
    "                progress = video_frame_idx / max(1, total_frames - 1)\n",
    "                bbox_idx = min(int(progress * (len(valid_bboxes) - 1)), len(valid_bboxes) - 1)\n",
    "                bbox_data = valid_bboxes[bbox_idx]\n",
    "            \n",
    "            bbox = bbox_data['bbox']\n",
    "            gavd_frame_num = bbox_data['frame_num']\n",
    "            \n",
    "            # Calculate crop region for this specific frame's bbox\n",
    "            crop_top = max(0, int(bbox['top']) - padding)\n",
    "            crop_left = max(0, int(bbox['left']) - padding)\n",
    "            crop_bottom = min(int(bbox['top'] + bbox['height']) + padding, height)\n",
    "            crop_right = min(int(bbox['left'] + bbox['width']) + padding, width)\n",
    "            \n",
    "            actual_crop_width = crop_right - crop_left\n",
    "            actual_crop_height = crop_bottom - crop_top\n",
    "            \n",
    "            # Show frame details if requested\n",
    "            if show_frame_details and video_frame_idx < 10:  # Show first 10 frames\n",
    "                print(f\"Frame {video_frame_idx:3d}: GAVD={gavd_frame_num}\")\n",
    "                print(f\"  üì¶ BBox: top={bbox['top']:.1f}, left={bbox['left']:.1f}, \"\n",
    "                      f\"width={bbox['width']:.1f}, height={bbox['height']:.1f}\")\n",
    "                print(f\"  ‚úÇÔ∏è Crop: ({crop_left},{crop_top}) to ({crop_right},{crop_bottom}) \"\n",
    "                      f\"= {actual_crop_width}x{actual_crop_height}\")\n",
    "            \n",
    "            # Crop the frame using this frame's specific bbox\n",
    "            cropped_frame = frame[crop_top:crop_bottom, crop_left:crop_right]\n",
    "            \n",
    "            # Create output frame with consistent dimensions (centered)\n",
    "            output_frame = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            # Center the cropped frame in the output frame\n",
    "            start_y = max(0, (output_height - actual_crop_height) // 2)\n",
    "            start_x = max(0, (output_width - actual_crop_width) // 2)\n",
    "            end_y = min(output_height, start_y + actual_crop_height)\n",
    "            end_x = min(output_width, start_x + actual_crop_width)\n",
    "            \n",
    "            # Ensure we don't exceed boundaries\n",
    "            crop_h = min(actual_crop_height, end_y - start_y)\n",
    "            crop_w = min(actual_crop_width, end_x - start_x)\n",
    "            \n",
    "            output_frame[start_y:start_y+crop_h, start_x:start_x+crop_w] = cropped_frame[:crop_h, :crop_w]\n",
    "            \n",
    "            out.write(output_frame)\n",
    "            frames_written += 1\n",
    "        \n",
    "        if show_frame_details and total_frames > 10:\n",
    "            print(f\"  ... (showing first 10 frames, total: {total_frames})\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"‚úÖ Per-frame cropped video saved: {frames_written} frames written\")\n",
    "        \n",
    "        # Verify output file\n",
    "        if frames_written == 0:\n",
    "            print(\"‚ö†Ô∏è Warning: No frames were written to output file!\")\n",
    "            return False\n",
    "        \n",
    "        if frames_written != total_frames:\n",
    "            print(f\"‚ö†Ô∏è Warning: Expected {total_frames} frames, but wrote {frames_written}\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error cropping video: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"üîß Per-frame dynamic cropping function defined successfully!\")\n",
    "print(\"‚úÇÔ∏è Uses exact per-frame bbox data from GAVD dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Batch video cropping function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def batch_crop_videos_only(video_dir, cropped_output_dir, gavd_df, max_videos=None, \n",
    "                          skip_existing=True, show_progress=True):\n",
    "    \"\"\"\n",
    "    Batch crop all videos using bounding box data without HSMR processing.\n",
    "    \n",
    "    Args:\n",
    "        video_dir (str): Directory containing input videos\n",
    "        cropped_output_dir (str): Directory to save cropped videos\n",
    "        gavd_df (pd.DataFrame): GAVD dataset with bounding box information\n",
    "        max_videos (int, optional): Maximum number of videos to process (for testing)\n",
    "        skip_existing (bool): Whether to skip already cropped videos\n",
    "        show_progress (bool): Whether to show progress bar and detailed info\n",
    "    \n",
    "    Returns:\n",
    "        dict: Cropping statistics and results\n",
    "    \"\"\"\n",
    "    if gavd_df is None:\n",
    "        print(\"‚ùå GAVD dataset not loaded. Cannot perform bounding box cropping.\")\n",
    "        return None\n",
    "    \n",
    "    # Get all video files\n",
    "    video_files = list(Path(video_dir).glob('*.mp4'))\n",
    "    \n",
    "    if max_videos:\n",
    "        video_files = video_files[:max_videos]\n",
    "    \n",
    "    print(f\"‚úÇÔ∏è Starting batch video cropping\")\n",
    "    print(f\"üìÅ Input directory: {video_dir}\")\n",
    "    print(f\"üìÅ Cropped output directory: {cropped_output_dir}\")\n",
    "    print(f\"üìº Total videos to process: {len(video_files)}\")\n",
    "    print(f\"‚è≠Ô∏è Skip existing: {skip_existing}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(cropped_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process videos with optional progress bar\n",
    "    iterator = tqdm(video_files, desc=\"Cropping videos\") if show_progress else video_files\n",
    "    \n",
    "    for i, video_path in enumerate(iterator, 1):\n",
    "        try:\n",
    "            sequence_id = video_path.stem\n",
    "            cropped_video_path = Path(cropped_output_dir) / f\"{sequence_id}_cropped.mp4\"\n",
    "            \n",
    "            # Skip if already exists and skip_existing is True\n",
    "            if skip_existing and cropped_video_path.exists():\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    print(f\"‚è≠Ô∏è [{i:4d}/{len(video_files):4d}] Skipping {video_path.name} - already cropped\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': True,\n",
    "                    'output': cropped_video_path,\n",
    "                    'skipped': True,\n",
    "                    'error': None,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get sequence bounding box data\n",
    "            sequence_data = get_sequence_bbox_data(sequence_id, gavd_df)\n",
    "            \n",
    "            if sequence_data is None:\n",
    "                error_msg = f\"No bounding box data found for sequence: {sequence_id}\"\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    print(f\"‚ö†Ô∏è [{i:4d}/{len(video_files):4d}] {video_path.name} - {error_msg}\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': False,\n",
    "                    'output': None,\n",
    "                    'skipped': False,\n",
    "                    'error': error_msg,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Perform per-frame cropping using GAVD bbox data\n",
    "            success = crop_video_with_bbox_per_frame(\n",
    "                str(video_path),\n",
    "                str(cropped_video_path),\n",
    "                sequence_data,\n",
    "                padding=20,\n",
    "                show_frame_details=False\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    output_size = cropped_video_path.stat().st_size / (1024*1024)\n",
    "                    print(f\"‚úÖ [{i:4d}/{len(video_files):4d}] {video_path.name} -> {output_size:.2f} MB\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': True,\n",
    "                    'output': cropped_video_path,\n",
    "                    'skipped': False,\n",
    "                    'error': None,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "            else:\n",
    "                error_msg = \"Cropping failed - see detailed output above\"\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    print(f\"‚ùå [{i:4d}/{len(video_files):4d}] {video_path.name} - {error_msg}\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': False,\n",
    "                    'output': None,\n",
    "                    'skipped': False,\n",
    "                    'error': error_msg,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "            \n",
    "            # Garbage collection every 50 videos\n",
    "            if i % 50 == 0:\n",
    "                gc.collect()\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Exception during cropping: {str(e)}\"\n",
    "            if show_progress and not isinstance(iterator, tqdm):\n",
    "                print(f\"üí• [{i:4d}/{len(video_files):4d}] {video_path.name} - {error_msg}\")\n",
    "            \n",
    "            results.append({\n",
    "                'video': video_path.name,\n",
    "                'success': False,\n",
    "                'output': None,\n",
    "                'skipped': False,\n",
    "                'error': error_msg,\n",
    "                'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = sum(1 for r in results if not r['success'])\n",
    "    skipped = sum(1 for r in results if r.get('skipped', False))\n",
    "    newly_cropped = successful - skipped\n",
    "    total_size_mb = sum(r['size_mb'] for r in results)\n",
    "    avg_time_per_video = total_time / len(results) if results else 0\n",
    "    \n",
    "    # Final garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    stats = {\n",
    "        'total_videos': len(results),\n",
    "        'successful': successful,\n",
    "        'failed': failed,\n",
    "        'skipped': skipped,\n",
    "        'newly_cropped': newly_cropped,\n",
    "        'total_time_seconds': total_time,\n",
    "        'avg_time_per_video': avg_time_per_video,\n",
    "        'total_size_mb': total_size_mb,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"üîß Batch video cropping function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Testing CORRECTED per-frame cropping...\n",
      "üß™ Testing PER-FRAME cropping for sequence: cljanb45y00083n6lmh1qhydd\n",
      "======================================================================\n",
      "üìã Sequence Information:\n",
      "  üìº Sequence ID: cljanb45y00083n6lmh1qhydd\n",
      "  üìä GAVD frames: 215\n",
      "  üéØ GAVD frame range: 2532 - 2746\n",
      "\n",
      "üì¶ Bounding Box Variation (showing per-frame changes):\n",
      "       first: top= 129.0, left= 805.0, width=247.0, height=485.0\n",
      "    frame 53: top= 127.3, left= 768.2, width=247.0, height=485.0\n",
      "   frame 107: top= 112.6, left= 659.3, width=278.4, height=501.1\n",
      "   frame 161: top= 121.8, left= 535.5, width=287.9, height=493.3\n",
      "        last: top= 131.0, left= 475.0, width=247.0, height=485.0\n",
      "\n",
      "‚úÇÔ∏è Testing Per-Frame Video Cropping:\n",
      "  üì• Input: GAVD-sequences\\cljanb45y00083n6lmh1qhydd.mp4 (0.46 MB)\n",
      "üé¨ Input video: 214 frames at 30 FPS (1280x720)\n",
      "üìã Sequence data: 215 frames\n",
      "üì¶ Found 215 valid bounding boxes\n",
      "üéØ GAVD frame range: 2532 to 2746 (215 frames)\n",
      "üéØ Video frame range: 0 to 213 (214 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 331x544 (max bbox + padding)\n",
      "\n",
      "üìã FRAME-BY-FRAME DETAILS:\n",
      "================================================================================\n",
      "Frame   0: GAVD=2532\n",
      "  üì¶ BBox: top=129.0, left=805.0, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (785,109) to (1072,634) = 287x525\n",
      "Frame   1: GAVD=2533\n",
      "  üì¶ BBox: top=129.0, left=804.3, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (784,108) to (1071,633) = 287x525\n",
      "Frame   2: GAVD=2534\n",
      "  üì¶ BBox: top=128.9, left=803.6, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (783,108) to (1070,633) = 287x525\n",
      "Frame   3: GAVD=2535\n",
      "  üì¶ BBox: top=128.9, left=802.9, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (782,108) to (1069,633) = 287x525\n",
      "Frame   4: GAVD=2536\n",
      "  üì¶ BBox: top=128.9, left=802.2, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (782,108) to (1069,633) = 287x525\n",
      "Frame   5: GAVD=2537\n",
      "  üì¶ BBox: top=128.8, left=801.5, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (781,108) to (1068,633) = 287x525\n",
      "Frame   6: GAVD=2538\n",
      "  üì¶ BBox: top=128.8, left=800.8, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (780,108) to (1067,633) = 287x525\n",
      "Frame   7: GAVD=2539\n",
      "  üì¶ BBox: top=128.8, left=800.1, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (780,108) to (1067,633) = 287x525\n",
      "Frame   8: GAVD=2540\n",
      "  üì¶ BBox: top=128.7, left=799.5, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (779,108) to (1066,633) = 287x525\n",
      "Frame   9: GAVD=2541\n",
      "  üì¶ BBox: top=128.7, left=798.8, width=247.0, height=485.0\n",
      "  ‚úÇÔ∏è Crop: (778,108) to (1065,633) = 287x525\n",
      "  ... (showing first 10 frames, total: 214)\n",
      "================================================================================\n",
      "‚úÖ Per-frame cropped video saved: 214 frames written\n",
      "  üì§ Output: GAVD-cropped-sequences\\cljanb45y00083n6lmh1qhydd_per_frame_test.mp4 (0.70 MB)\n",
      "  üìä Size change: 1.52x original\n",
      "  ‚úÖ Per-frame cropping test SUCCESSFUL!\n",
      "  üìä Output video: 214 frames, 330x544\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the corrected per-frame cropping function\n",
    "def test_per_frame_cropping(sequence_id=\"cljanb45y00083n6lmh1qhydd\"):\n",
    "    \"\"\"Test the corrected per-frame bounding box cropping functionality.\"\"\"\n",
    "    \n",
    "    if gavd_dataset is None:\n",
    "        print(\"‚ùå GAVD dataset not loaded. Cannot test per-frame cropping.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üß™ Testing PER-FRAME cropping for sequence: {sequence_id}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get sequence data\n",
    "    sequence_data = get_sequence_bbox_data(sequence_id, gavd_dataset)\n",
    "    \n",
    "    if sequence_data is None:\n",
    "        print(f\"‚ùå No data found for sequence: {sequence_id}\")\n",
    "        return\n",
    "    \n",
    "    # Check video file\n",
    "    input_video = Path(GAVD_SEQUENCES_DIR) / f\"{sequence_id}.mp4\"\n",
    "    if not input_video.exists():\n",
    "        print(f\"‚ùå Input video not found: {input_video}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìã Sequence Information:\")\n",
    "    print(f\"  üìº Sequence ID: {sequence_id}\")\n",
    "    print(f\"  üìä GAVD frames: {len(sequence_data)}\")\n",
    "    print(f\"  üéØ GAVD frame range: {sequence_data['frame_num'].min()} - {sequence_data['frame_num'].max()}\")\n",
    "    \n",
    "    # Show bbox variation to demonstrate per-frame differences\n",
    "    valid_bboxes = [bbox for bbox in sequence_data['bbox_parsed'] if bbox is not None]\n",
    "    if len(valid_bboxes) >= 5:\n",
    "        print(f\"\\nüì¶ Bounding Box Variation (showing per-frame changes):\")\n",
    "        for i in [0, len(valid_bboxes)//4, len(valid_bboxes)//2, 3*len(valid_bboxes)//4, -1]:\n",
    "            bbox = valid_bboxes[i]\n",
    "            frame_idx = \"first\" if i == 0 else \"last\" if i == -1 else f\"frame {i}\"\n",
    "            print(f\"  {frame_idx:>10}: top={bbox['top']:6.1f}, left={bbox['left']:6.1f}, \"\n",
    "                  f\"width={bbox['width']:5.1f}, height={bbox['height']:5.1f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÇÔ∏è Testing Per-Frame Video Cropping:\")\n",
    "    print(f\"  üì• Input: {input_video} ({input_video.stat().st_size / (1024*1024):.2f} MB)\")\n",
    "    \n",
    "    # Clean up any existing test files\n",
    "    test_output = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_per_frame_test.mp4\"\n",
    "    if test_output.exists():\n",
    "        test_output.unlink()\n",
    "        print(f\"  üóëÔ∏è Removed existing test file\")\n",
    "    \n",
    "    # Perform per-frame cropping with frame details\n",
    "    success = crop_video_with_bbox_per_frame(\n",
    "        str(input_video), \n",
    "        str(test_output), \n",
    "        sequence_data,\n",
    "        padding=20,\n",
    "        show_frame_details=True  # Show detailed frame-by-frame info\n",
    "    )\n",
    "    \n",
    "    if success and test_output.exists():\n",
    "        output_size_mb = test_output.stat().st_size / (1024*1024)\n",
    "        input_size_mb = input_video.stat().st_size / (1024*1024)\n",
    "        \n",
    "        print(f\"  üì§ Output: {test_output} ({output_size_mb:.2f} MB)\")\n",
    "        print(f\"  üìä Size change: {output_size_mb/input_size_mb:.2f}x original\")\n",
    "        \n",
    "        if output_size_mb > 0.01:  # Check if file has reasonable size\n",
    "            print(f\"  ‚úÖ Per-frame cropping test SUCCESSFUL!\")\n",
    "            \n",
    "            # Verify the output video can be opened\n",
    "            test_cap = cv2.VideoCapture(str(test_output))\n",
    "            if test_cap.isOpened():\n",
    "                test_frames = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                test_width = int(test_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                test_height = int(test_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                test_cap.release()\n",
    "                print(f\"  üìä Output video: {test_frames} frames, {test_width}x{test_height}\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Output video cannot be opened!\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Output file too small - cropping may have failed!\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"  ‚ùå Per-frame cropping test FAILED!\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Run the per-frame cropping test\n",
    "print(\"üîÑ Testing CORRECTED per-frame cropping...\")\n",
    "test_per_frame_cropping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÇÔ∏è Starting batch video cropping\n",
      "üìÅ Input directory: ./GAVD-sequences\n",
      "üìÅ Cropped output directory: ./GAVD-cropped-sequences\n",
      "üìº Total videos to process: 1801\n",
      "‚è≠Ô∏è Skip existing: True\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 0/1801 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Input video: 511 frames at 30 FPS (1280x720)\n",
      "üìã Sequence data: 512 frames\n",
      "üì¶ Found 512 valid bounding boxes\n",
      "üéØ GAVD frame range: 1757 to 2268 (512 frames)\n",
      "üéØ Video frame range: 0 to 510 (511 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 337x551 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 1/1801 [00:01<30:30,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 511 frames written\n",
      "üé¨ Input video: 214 frames at 30 FPS (1280x720)\n",
      "üìã Sequence data: 215 frames\n",
      "üì¶ Found 215 valid bounding boxes\n",
      "üéØ GAVD frame range: 2532 to 2746 (215 frames)\n",
      "üéØ Video frame range: 0 to 213 (214 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 331x544 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 2/1801 [00:01<20:26,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 214 frames written\n",
      "üé¨ Input video: 147 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 148 frames\n",
      "üì¶ Found 148 valid bounding boxes\n",
      "üéØ GAVD frame range: 1 to 148 (148 frames)\n",
      "üéØ Video frame range: 0 to 146 (147 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 544x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 3/1801 [00:02<20:03,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 147 frames written\n",
      "üé¨ Input video: 150 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 151 frames\n",
      "üì¶ Found 151 valid bounding boxes\n",
      "üéØ GAVD frame range: 205 to 355 (151 frames)\n",
      "üéØ Video frame range: 0 to 149 (150 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 598x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 4/1801 [00:02<20:16,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 150 frames written\n",
      "üé¨ Input video: 431 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 432 frames\n",
      "üì¶ Found 432 valid bounding boxes\n",
      "üéØ GAVD frame range: 382 to 813 (432 frames)\n",
      "üéØ Video frame range: 0 to 430 (431 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 590x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 5/1801 [00:04<32:52,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 431 frames written\n",
      "üé¨ Input video: 490 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 491 frames\n",
      "üì¶ Found 491 valid bounding boxes\n",
      "üéØ GAVD frame range: 852 to 1342 (491 frames)\n",
      "üéØ Video frame range: 0 to 489 (490 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 587x759 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 6/1801 [00:06<42:53,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 490 frames written\n",
      "üé¨ Input video: 178 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 179 frames\n",
      "üì¶ Found 179 valid bounding boxes\n",
      "üéØ GAVD frame range: 1346 to 1524 (179 frames)\n",
      "üéØ Video frame range: 0 to 177 (178 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 363x718 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 7/1801 [00:07<35:40,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 178 frames written\n",
      "üé¨ Input video: 177 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 178 frames\n",
      "üì¶ Found 178 valid bounding boxes\n",
      "üéØ GAVD frame range: 1579 to 1756 (178 frames)\n",
      "üéØ Video frame range: 0 to 176 (177 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 449x748 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 8/1801 [00:08<31:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 177 frames written\n",
      "üé¨ Input video: 369 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 370 frames\n",
      "üì¶ Found 370 valid bounding boxes\n",
      "üéØ GAVD frame range: 1788 to 2157 (370 frames)\n",
      "üéØ Video frame range: 0 to 368 (369 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 385x731 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 9/1801 [00:09<34:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 369 frames written\n",
      "üé¨ Input video: 508 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 509 frames\n",
      "üì¶ Found 509 valid bounding boxes\n",
      "üéØ GAVD frame range: 2185 to 2693 (509 frames)\n",
      "üéØ Video frame range: 0 to 507 (508 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 421x721 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|          | 13/1801 [00:11<18:21,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 508 frames written\n",
      "üé¨ Input video: 112 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 113 frames\n",
      "üì¶ Found 113 valid bounding boxes\n",
      "üéØ GAVD frame range: 38 to 150 (113 frames)\n",
      "üéØ Video frame range: 0 to 111 (112 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 111x259 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 112 frames written\n",
      "üé¨ Input video: 118 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 119 frames\n",
      "üì¶ Found 119 valid bounding boxes\n",
      "üéØ GAVD frame range: 195 to 313 (119 frames)\n",
      "üéØ Video frame range: 0 to 117 (118 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 111x268 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 118 frames written\n",
      "üé¨ Input video: 113 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 114 frames\n",
      "üì¶ Found 114 valid bounding boxes\n",
      "üéØ GAVD frame range: 350 to 463 (114 frames)\n",
      "üéØ Video frame range: 0 to 112 (113 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 111x267 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 113 frames written\n",
      "üé¨ Input video: 103 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 104 frames\n",
      "üì¶ Found 104 valid bounding boxes\n",
      "üéØ GAVD frame range: 842 to 945 (104 frames)\n",
      "üéØ Video frame range: 0 to 102 (103 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 117x272 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 103 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|          | 19/1801 [00:11<07:01,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Input video: 87 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 88 frames\n",
      "üì¶ Found 88 valid bounding boxes\n",
      "üéØ GAVD frame range: 1312 to 1399 (88 frames)\n",
      "üéØ Video frame range: 0 to 86 (87 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 136x266 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 87 frames written\n",
      "üé¨ Input video: 97 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 98 frames\n",
      "üì¶ Found 98 valid bounding boxes\n",
      "üéØ GAVD frame range: 1477 to 1574 (98 frames)\n",
      "üéØ Video frame range: 0 to 96 (97 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 120x278 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 97 frames written\n",
      "üé¨ Input video: 111 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 112 frames\n",
      "üì¶ Found 112 valid bounding boxes\n",
      "üéØ GAVD frame range: 1615 to 1726 (112 frames)\n",
      "üéØ Video frame range: 0 to 110 (111 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 117x246 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 111 frames written\n",
      "üé¨ Input video: 90 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 91 frames\n",
      "üì¶ Found 91 valid bounding boxes\n",
      "üéØ GAVD frame range: 1785 to 1875 (91 frames)\n",
      "üéØ Video frame range: 0 to 89 (90 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 115x260 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 90 frames written\n",
      "üé¨ Input video: 95 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 96 frames\n",
      "üì¶ Found 96 valid bounding boxes\n",
      "üéØ GAVD frame range: 1926 to 2021 (96 frames)\n",
      "üéØ Video frame range: 0 to 94 (95 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 101x239 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 95 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|          | 22/1801 [00:11<04:57,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Input video: 98 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 99 frames\n",
      "üì¶ Found 99 valid bounding boxes\n",
      "üéØ GAVD frame range: 2104 to 2202 (99 frames)\n",
      "üéØ Video frame range: 0 to 97 (98 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 109x260 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 98 frames written\n",
      "üé¨ Input video: 104 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 105 frames\n",
      "üì¶ Found 105 valid bounding boxes\n",
      "üéØ GAVD frame range: 2248 to 2352 (105 frames)\n",
      "üéØ Video frame range: 0 to 103 (104 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 105x249 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 104 frames written\n",
      "üé¨ Input video: 104 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 105 frames\n",
      "üì¶ Found 105 valid bounding boxes\n",
      "üéØ GAVD frame range: 2424 to 2528 (105 frames)\n",
      "üéØ Video frame range: 0 to 103 (104 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 110x249 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 104 frames written\n",
      "üé¨ Input video: 96 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 97 frames\n",
      "üì¶ Found 97 valid bounding boxes\n",
      "üéØ GAVD frame range: 2571 to 2667 (97 frames)\n",
      "üéØ Video frame range: 0 to 95 (96 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 138x254 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 96 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|‚ñè         | 27/1801 [00:12<03:07,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Input video: 108 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 109 frames\n",
      "üì¶ Found 109 valid bounding boxes\n",
      "üéØ GAVD frame range: 2754 to 2862 (109 frames)\n",
      "üéØ Video frame range: 0 to 107 (108 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 96x258 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 108 frames written\n",
      "üé¨ Input video: 99 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 100 frames\n",
      "üì¶ Found 100 valid bounding boxes\n",
      "üéØ GAVD frame range: 2901 to 3000 (100 frames)\n",
      "üéØ Video frame range: 0 to 98 (99 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 142x263 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 99 frames written\n",
      "üé¨ Input video: 100 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 101 frames\n",
      "üì¶ Found 101 valid bounding boxes\n",
      "üéØ GAVD frame range: 3083 to 3183 (101 frames)\n",
      "üéØ Video frame range: 0 to 99 (100 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 104x241 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 100 frames written\n",
      "üé¨ Input video: 116 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 117 frames\n",
      "üì¶ Found 117 valid bounding boxes\n",
      "üéØ GAVD frame range: 3226 to 3342 (117 frames)\n",
      "üéØ Video frame range: 0 to 115 (116 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 137x300 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 116 frames written\n",
      "üé¨ Input video: 111 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 112 frames\n",
      "üì¶ Found 112 valid bounding boxes\n",
      "üéØ GAVD frame range: 3395 to 3506 (112 frames)\n",
      "üéØ Video frame range: 0 to 110 (111 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 127x307 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 111 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|‚ñè         | 30/1801 [00:12<02:33, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Input video: 104 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 105 frames\n",
      "üì¶ Found 105 valid bounding boxes\n",
      "üéØ GAVD frame range: 3549 to 3653 (105 frames)\n",
      "üéØ Video frame range: 0 to 103 (104 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 140x325 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 104 frames written\n",
      "üé¨ Input video: 98 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 99 frames\n",
      "üì¶ Found 99 valid bounding boxes\n",
      "üéØ GAVD frame range: 3709 to 3807 (99 frames)\n",
      "üéØ Video frame range: 0 to 97 (98 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 131x314 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 98 frames written\n",
      "üé¨ Input video: 82 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 83 frames\n",
      "üì¶ Found 83 valid bounding boxes\n",
      "üéØ GAVD frame range: 3855 to 3937 (83 frames)\n",
      "üéØ Video frame range: 0 to 81 (82 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 176x330 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 82 frames written\n",
      "üé¨ Input video: 90 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 91 frames\n",
      "üì¶ Found 91 valid bounding boxes\n",
      "üéØ GAVD frame range: 3994 to 4084 (91 frames)\n",
      "üéØ Video frame range: 0 to 89 (90 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 111x309 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 90 frames written\n",
      "üé¨ Input video: 99 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 100 frames\n",
      "üì¶ Found 100 valid bounding boxes\n",
      "üéØ GAVD frame range: 4129 to 4228 (100 frames)\n",
      "üéØ Video frame range: 0 to 98 (99 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 142x304 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|‚ñè         | 36/1801 [00:12<01:59, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 99 frames written\n",
      "üé¨ Input video: 124 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 125 frames\n",
      "üì¶ Found 125 valid bounding boxes\n",
      "üéØ GAVD frame range: 4271 to 4395 (125 frames)\n",
      "üéØ Video frame range: 0 to 123 (124 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 116x291 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 124 frames written\n",
      "üé¨ Input video: 128 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 129 frames\n",
      "üì¶ Found 129 valid bounding boxes\n",
      "üéØ GAVD frame range: 4437 to 4565 (129 frames)\n",
      "üéØ Video frame range: 0 to 127 (128 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 178x348 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 128 frames written\n",
      "üé¨ Input video: 81 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 82 frames\n",
      "üì¶ Found 82 valid bounding boxes\n",
      "üéØ GAVD frame range: 4604 to 4685 (82 frames)\n",
      "üéØ Video frame range: 0 to 80 (81 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 124x332 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 81 frames written\n",
      "üé¨ Input video: 95 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 96 frames\n",
      "üì¶ Found 96 valid bounding boxes\n",
      "üéØ GAVD frame range: 4725 to 4820 (96 frames)\n",
      "üéØ Video frame range: 0 to 94 (95 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 156x381 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|‚ñè         | 39/1801 [00:12<01:47, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 95 frames written\n",
      "üé¨ Input video: 69 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 70 frames\n",
      "üì¶ Found 70 valid bounding boxes\n",
      "üéØ GAVD frame range: 4891 to 4960 (70 frames)\n",
      "üéØ Video frame range: 0 to 68 (69 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 134x334 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 69 frames written\n",
      "üé¨ Input video: 80 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 81 frames\n",
      "üì¶ Found 81 valid bounding boxes\n",
      "üéØ GAVD frame range: 5002 to 5082 (81 frames)\n",
      "üéØ Video frame range: 0 to 79 (80 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 135x352 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 80 frames written\n",
      "üé¨ Input video: 33 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 34 frames\n",
      "üì¶ Found 34 valid bounding boxes\n",
      "üéØ GAVD frame range: 5191 to 5224 (34 frames)\n",
      "üéØ Video frame range: 0 to 32 (33 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 107x256 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 33 frames written\n",
      "üé¨ Input video: 38 frames at 30 FPS (272x480)\n",
      "üìã Sequence data: 39 frames\n",
      "üì¶ Found 39 valid bounding boxes\n",
      "üéØ GAVD frame range: 5269 to 5307 (39 frames)\n",
      "üéØ Video frame range: 0 to 37 (38 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 125x296 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 38 frames written\n",
      "üé¨ Input video: 305 frames at 29 FPS (1920x1080)\n",
      "üìã Sequence data: 306 frames\n",
      "üì¶ Found 306 valid bounding boxes\n",
      "üéØ GAVD frame range: 1 to 306 (306 frames)\n",
      "üéØ Video frame range: 0 to 304 (305 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 492x701 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|‚ñè         | 42/1801 [00:14<05:07,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 305 frames written\n",
      "üé¨ Input video: 259 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 260 frames\n",
      "üì¶ Found 260 valid bounding boxes\n",
      "üéØ GAVD frame range: 1 to 260 (260 frames)\n",
      "üéØ Video frame range: 0 to 258 (259 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 448x753 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|‚ñè         | 44/1801 [00:15<07:18,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 259 frames written\n",
      "üé¨ Input video: 300 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 301 frames\n",
      "üì¶ Found 301 valid bounding boxes\n",
      "üéØ GAVD frame range: 390 to 690 (301 frames)\n",
      "üéØ Video frame range: 0 to 299 (300 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 408x732 (max bbox + padding)\n",
      "‚úÖ Per-frame cropped video saved: 300 frames written\n",
      "üé¨ Input video: 1037 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 1038 frames\n",
      "üì¶ Found 1038 valid bounding boxes\n",
      "üéØ GAVD frame range: 761 to 1798 (1038 frames)\n",
      "üéØ Video frame range: 0 to 1036 (1037 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 489x756 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 46/1801 [00:20<25:16,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 1037 frames written\n",
      "üé¨ Input video: 227 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 228 frames\n",
      "üì¶ Found 228 valid bounding boxes\n",
      "üéØ GAVD frame range: 3865 to 4092 (228 frames)\n",
      "üéØ Video frame range: 0 to 226 (227 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 312x733 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 48/1801 [00:21<23:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 227 frames written\n",
      "üé¨ Input video: 228 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 229 frames\n",
      "üì¶ Found 229 valid bounding boxes\n",
      "üéØ GAVD frame range: 4204 to 4432 (229 frames)\n",
      "üéØ Video frame range: 0 to 227 (228 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 266x672 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 49/1801 [00:22<24:51,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 228 frames written\n",
      "üé¨ Input video: 941 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 942 frames\n",
      "üì¶ Found 942 valid bounding boxes\n",
      "üéØ GAVD frame range: 4635 to 5576 (942 frames)\n",
      "üéØ Video frame range: 0 to 940 (941 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 315x738 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 50/1801 [00:28<48:42,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 941 frames written\n",
      "üé¨ Input video: 888 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 889 frames\n",
      "üì¶ Found 889 valid bounding boxes\n",
      "üéØ GAVD frame range: 6010 to 6898 (889 frames)\n",
      "üéØ Video frame range: 0 to 887 (888 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 272x674 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 51/1801 [00:32<1:06:14,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 888 frames written\n",
      "üé¨ Input video: 328 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 329 frames\n",
      "üì¶ Found 329 valid bounding boxes\n",
      "üéØ GAVD frame range: 1 to 329 (329 frames)\n",
      "üéØ Video frame range: 0 to 327 (328 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 335x758 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 52/1801 [00:34<1:03:29,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 328 frames written\n",
      "üé¨ Input video: 343 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 344 frames\n",
      "üì¶ Found 344 valid bounding boxes\n",
      "üéØ GAVD frame range: 429 to 772 (344 frames)\n",
      "üéØ Video frame range: 0 to 342 (343 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 363x743 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 53/1801 [00:36<1:02:38,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 343 frames written\n",
      "üé¨ Input video: 1108 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 1109 frames\n",
      "üì¶ Found 1109 valid bounding boxes\n",
      "üéØ GAVD frame range: 792 to 1900 (1109 frames)\n",
      "üéØ Video frame range: 0 to 1107 (1108 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 354x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 54/1801 [00:42<1:29:46,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Per-frame cropped video saved: 1108 frames written\n",
      "üé¨ Input video: 1225 frames at 60 FPS (1920x1080)\n",
      "üìã Sequence data: 1226 frames\n",
      "üì¶ Found 1226 valid bounding boxes\n",
      "üéØ GAVD frame range: 1937 to 3162 (1226 frames)\n",
      "üéØ Video frame range: 0 to 1224 (1225 frames)\n",
      "‚úÇÔ∏è Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "üìè Output video size: 355x728 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|‚ñé         | 54/1801 [00:43<23:29,  1.24it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run batch video cropping for all sequences\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This will create cropped videos for all sequences without running HSMR\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# For full processing: process all videos\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m crop_stats \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_crop_videos_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGAVD_SEQUENCES_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCROPPED_VIDEOS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgavd_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmax_videos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_existing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m crop_stats:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 82\u001b[0m, in \u001b[0;36mbatch_crop_videos_only\u001b[1;34m(video_dir, cropped_output_dir, gavd_df, max_videos, skip_existing, show_progress)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Perform per-frame cropping using GAVD bbox data\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[43mcrop_video_with_bbox_per_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcropped_video_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_frame_details\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m show_progress \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iterator, tqdm):\n",
      "Cell \u001b[1;32mIn[22], line 92\u001b[0m, in \u001b[0;36mcrop_video_with_bbox_per_frame\u001b[1;34m(input_video_path, output_video_path, sequence_data, padding, show_frame_details)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Process each video frame with corresponding bbox\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_frame_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_frames):\n\u001b[1;32m---> 92\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run batch video cropping for all sequences\n",
    "# This will create cropped videos for all sequences without running HSMR\n",
    "\n",
    "# For testing: process only a few videos\n",
    "# crop_stats = batch_crop_videos_only(GAVD_SEQUENCES_DIR, CROPPED_VIDEOS_DIR, gavd_dataset, \n",
    "#                                   max_videos=10, skip_existing=True, show_progress=True)\n",
    "\n",
    "# For full processing: process all videos\n",
    "crop_stats = batch_crop_videos_only(GAVD_SEQUENCES_DIR, CROPPED_VIDEOS_DIR, gavd_dataset, \n",
    "                                  max_videos=None, skip_existing=True, show_progress=True)\n",
    "\n",
    "if crop_stats:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÇÔ∏è BATCH VIDEO CROPPING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìº Total videos processed: {crop_stats['total_videos']}\")\n",
    "    print(f\"‚úÖ Successfully cropped: {crop_stats['successful']}\")\n",
    "    print(f\"‚ùå Failed to crop: {crop_stats['failed']}\")\n",
    "    print(f\"‚è≠Ô∏è Skipped (already existed): {crop_stats['skipped']}\")\n",
    "    print(f\"üÜï Newly cropped: {crop_stats['newly_cropped']}\")\n",
    "    print(f\"‚è±Ô∏è Total time: {crop_stats['total_time_seconds']:.2f} seconds ({crop_stats['total_time_seconds']/60:.1f} minutes)\")\n",
    "    print(f\"‚ö° Average time per video: {crop_stats['avg_time_per_video']:.2f} seconds\")\n",
    "    print(f\"üíæ Total input size: {crop_stats['total_size_mb']:.1f} MB\")\n",
    "    \n",
    "    # Show failed videos if any\n",
    "    if crop_stats['failed'] > 0:\n",
    "        print(f\"\\n‚ùå Failed cropping videos:\")\n",
    "        failed_videos = [r for r in crop_stats['results'] if not r['success']]\n",
    "        for failed in failed_videos[:10]:  # Show first 10 failures\n",
    "            print(f\"  - {failed['video']}: {failed['error']}\")\n",
    "        if len(failed_videos) > 10:\n",
    "            print(f\"  ... and {len(failed_videos) - 10} more failures\")\n",
    "    \n",
    "    # Show cropped videos directory info\n",
    "    print(f\"\\nüìÅ Cropped videos saved to: {CROPPED_VIDEOS_DIR}\")\n",
    "    cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "    if cropped_videos:\n",
    "        total_cropped_size = sum(v.stat().st_size for v in cropped_videos) / (1024*1024)\n",
    "        print(f\"‚úÇÔ∏è Total cropped videos: {len(cropped_videos)} ({total_cropped_size:.1f} MB total)\")\n",
    "        \n",
    "        # Show some statistics about the cropped videos\n",
    "        sample_videos = cropped_videos[:5]\n",
    "        print(f\"\\nüìä Sample cropped videos:\")\n",
    "        for video in sample_videos:\n",
    "            size_mb = video.stat().st_size / (1024*1024)\n",
    "            print(f\"  üìÑ {video.name} ({size_mb:.2f} MB)\")\n",
    "        if len(cropped_videos) > 5:\n",
    "            print(f\"  ... and {len(cropped_videos) - 5} more\")\n",
    "    else:\n",
    "        print(\"‚úÇÔ∏è No cropped videos found\")\n",
    "        \n",
    "    print(f\"\\nüéØ Success rate: {crop_stats['successful']/crop_stats['total_videos']*100:.1f}%\")\n",
    "else:\n",
    "    print(\"‚ùå Cropping operation failed to initialize\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
