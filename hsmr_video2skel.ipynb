{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# GAVD Video to HSMR Skeleton Parameters Pipeline\n",
    "\n",
    "This notebook processes GAVD videos using the HSMR model to extract skeleton parameters. The pipeline converts video files into `.npy` files containing skeletal motion data.\n",
    "\n",
    "## Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete!\n",
      "ğŸ“ Input directory: ./GAVD-sequences\n",
      "ğŸ“ Cropped videos directory: ./GAVD-cropped-sequences\n",
      "ğŸ“ Output directory: ./GAVD-hsmr-params\n",
      "ğŸ¥ Total videos found: 1801\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ast\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Add HSMR to path\n",
    "sys.path.append('./HSMR')\n",
    "\n",
    "# Configuration\n",
    "GAVD_SEQUENCES_DIR = \"./GAVD-sequences\"\n",
    "OUTPUT_DIR = \"./GAVD-hsmr-params\"\n",
    "HSMR_SCRIPT = \"./HSMR/exp/run_demo.py\"\n",
    "GAVD_DATA_DIR = \"./GAVD/data\"\n",
    "CROPPED_VIDEOS_DIR = \"./GAVD-cropped-sequences\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(CROPPED_VIDEOS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Setup complete!\")\n",
    "print(f\"ğŸ“ Input directory: {GAVD_SEQUENCES_DIR}\")\n",
    "print(f\"ğŸ“ Cropped videos directory: {CROPPED_VIDEOS_DIR}\")\n",
    "print(f\"ğŸ“ Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"ğŸ¥ Total videos found: {len(list(Path(GAVD_SEQUENCES_DIR).glob('*.mp4')))}\")\n",
    "\n",
    "# set $env:PYOPENGL_PLATFORM = \"pyglet\" for HSMR\n",
    "os.environ['PYOPENGL_PLATFORM'] = 'pyglet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Loading GAVD dataset...\n",
      "  Loading GAVD_Clinical_Annotations_1.csv...\n",
      "    Shape: (91624, 10)\n",
      "  Loading GAVD_Clinical_Annotations_2.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1nkas-Strix-4090-ll\\AppData\\Local\\Temp\\ipykernel_33824\\1934443960.py:17: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_part = pd.read_csv(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Shape: (91623, 10)\n",
      "  Loading GAVD_Clinical_Annotations_3.csv...\n",
      "    Shape: (91623, 10)\n",
      "  Loading GAVD_Clinical_Annotations_4.csv...\n",
      "    Shape: (91623, 10)\n",
      "  Loading GAVD_Clinical_Annotations_5.csv...\n",
      "    Shape: (91623, 10)\n",
      "âœ… Complete dataset loaded: (458116, 10)\n",
      "ğŸ“¼ Total unique sequences: 1874\n",
      "ğŸ”§ UPDATED function with bounding box cropping defined successfully!\n",
      "ğŸ“ Model path: ./HSMR/data_inputs/released_models/HSMR-ViTH-r1d1\n",
      "âœ‚ï¸ Bounding box cropping: ENABLED\n"
     ]
    }
   ],
   "source": [
    "# Load GAVD dataset with bounding box information\n",
    "def load_gavd_dataset() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the complete GAVD dataset from CSV files.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Complete dataset with bounding box information\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“Š Loading GAVD dataset...\")\n",
    "    all_dfs = []\n",
    "    \n",
    "    for i in range(1, 6):  # Parts 1-5\n",
    "        filename = f'GAVD_Clinical_Annotations_{i}.csv'\n",
    "        filepath = Path(GAVD_DATA_DIR) / filename\n",
    "        if filepath.exists():\n",
    "            print(f\"  Loading {filename}...\")\n",
    "            df_part = pd.read_csv(filepath)\n",
    "            all_dfs.append(df_part)\n",
    "            print(f\"    Shape: {df_part.shape}\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        df_complete = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(f\"âœ… Complete dataset loaded: {df_complete.shape}\")\n",
    "        print(f\"ğŸ“¼ Total unique sequences: {df_complete['seq'].nunique()}\")\n",
    "        return df_complete\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No GAVD CSV files found!\")\n",
    "\n",
    "def parse_bbox_string(bbox_str: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse bounding box string to dictionary.\n",
    "    \n",
    "    Args:\n",
    "        bbox_str (str): String representation of bounding box dict\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Parsed bounding box with keys: top, left, height, width\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(bbox_str) or bbox_str == 'nan':\n",
    "            return None\n",
    "        # Use ast.literal_eval to safely parse the string representation of dict\n",
    "        bbox_dict = ast.literal_eval(bbox_str)\n",
    "        return bbox_dict\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"âš ï¸ Error parsing bbox: {bbox_str} - {e}\")\n",
    "        return None\n",
    "\n",
    "def get_sequence_bbox_data(sequence_id: str, gavd_df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get bounding box data for a specific sequence.\n",
    "    \n",
    "    Args:\n",
    "        sequence_id (str): The sequence ID to lookup\n",
    "        gavd_df (pd.DataFrame): The GAVD dataset\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: Sequence data with bounding boxes, sorted by frame number\n",
    "    \"\"\"\n",
    "    sequence_data = gavd_df[gavd_df['seq'] == sequence_id].copy()\n",
    "    \n",
    "    if sequence_data.empty:\n",
    "        print(f\"âš ï¸ No bounding box data found for sequence: {sequence_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Sort by frame number\n",
    "    sequence_data = sequence_data.sort_values('frame_num').reset_index(drop=True)\n",
    "    \n",
    "    # Parse bounding box strings\n",
    "    sequence_data['bbox_parsed'] = sequence_data['bbox'].apply(parse_bbox_string)\n",
    "    \n",
    "    return sequence_data\n",
    "\n",
    "def crop_video_with_bbox(input_video_path: str, output_video_path: str, \n",
    "                        sequence_data: pd.DataFrame, padding: int = 20) -> bool:\n",
    "    \"\"\"\n",
    "    Crop video using bounding box data from GAVD dataset.\n",
    "    \n",
    "    Args:\n",
    "        input_video_path (str): Path to input video\n",
    "        output_video_path (str): Path to save cropped video\n",
    "        sequence_data (pd.DataFrame): Sequence data with bounding boxes\n",
    "        padding (int): Extra padding around bounding box\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open input video\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"âŒ Cannot open video: {input_video_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"ğŸ¬ Input video: {total_frames} frames at {fps} FPS\")\n",
    "        print(f\"ğŸ“‹ Sequence data: {len(sequence_data)} frames\")\n",
    "        \n",
    "        # Create frame number to bbox mapping\n",
    "        bbox_map = {}\n",
    "        for _, row in sequence_data.iterrows():\n",
    "            frame_num = row['frame_num']\n",
    "            bbox = row['bbox_parsed']\n",
    "            if bbox is not None:\n",
    "                bbox_map[frame_num] = bbox\n",
    "        \n",
    "        if not bbox_map:\n",
    "            print(\"âŒ No valid bounding boxes found!\")\n",
    "            return False\n",
    "        \n",
    "        # Calculate consistent crop region from all bounding boxes\n",
    "        all_tops = [bbox['top'] for bbox in bbox_map.values()]\n",
    "        all_lefts = [bbox['left'] for bbox in bbox_map.values()]\n",
    "        all_bottoms = [bbox['top'] + bbox['height'] for bbox in bbox_map.values()]\n",
    "        all_rights = [bbox['left'] + bbox['width'] for bbox in bbox_map.values()]\n",
    "        \n",
    "        # Use the bounding box that encompasses all person positions\n",
    "        crop_top = max(0, int(min(all_tops)) - padding)\n",
    "        crop_left = max(0, int(min(all_lefts)) - padding)\n",
    "        crop_bottom = int(max(all_bottoms)) + padding\n",
    "        crop_right = int(max(all_rights)) + padding\n",
    "        \n",
    "        # Get video dimensions for validation\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        crop_bottom = min(crop_bottom, height)\n",
    "        crop_right = min(crop_right, width)\n",
    "        \n",
    "        crop_width = crop_right - crop_left\n",
    "        crop_height = crop_bottom - crop_top\n",
    "        \n",
    "        print(f\"ğŸ“ Crop region: ({crop_left}, {crop_top}) to ({crop_right}, {crop_bottom})\")\n",
    "        print(f\"ğŸ“ Crop size: {crop_width}x{crop_height}\")\n",
    "        \n",
    "        # Setup output video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (crop_width, crop_height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"âŒ Cannot create output video: {output_video_path}\")\n",
    "            cap.release()\n",
    "            return False\n",
    "        \n",
    "        # FIXED: Handle frame number mismatch by processing ALL video frames\n",
    "        # The sequence frames from GAVD may not correspond directly to video frame indices\n",
    "        sequence_frames = set(sequence_data['frame_num'].values)\n",
    "        min_frame = min(sequence_frames)\n",
    "        max_frame = max(sequence_frames)\n",
    "        \n",
    "        print(f\"ğŸ¯ GAVD frame range: {min_frame} to {max_frame}\")\n",
    "        print(f\"ğŸ¯ Video frame range: 0 to {total_frames-1}\")\n",
    "        \n",
    "        # Since the frame numbers don't match video indices, process all video frames\n",
    "        # and use the bounding box information proportionally\n",
    "        frame_idx = 0\n",
    "        frames_written = 0\n",
    "        \n",
    "        # Create a sorted list of bounding boxes for interpolation\n",
    "        sorted_bboxes = [(row['frame_num'], row['bbox_parsed']) for _, row in sequence_data.iterrows() \n",
    "                        if row['bbox_parsed'] is not None]\n",
    "        sorted_bboxes.sort(key=lambda x: x[0])\n",
    "        \n",
    "        if not sorted_bboxes:\n",
    "            print(\"âŒ No valid bounding boxes found after sorting!\")\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            return False\n",
    "        \n",
    "        print(f\"ğŸ“¦ Using {len(sorted_bboxes)} bounding boxes for cropping\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Use a consistent bounding box for all frames (could be improved with interpolation)\n",
    "            # For now, use the first valid bounding box\n",
    "            bbox = sorted_bboxes[0][1]  # Use first bbox\n",
    "            \n",
    "            # Dynamic crop based on current bbox (optional: interpolate between bboxes)\n",
    "            # For consistency, we'll use the pre-calculated crop region\n",
    "            cropped_frame = frame[crop_top:crop_bottom, crop_left:crop_right]\n",
    "            out.write(cropped_frame)\n",
    "            frames_written += 1\n",
    "            \n",
    "            frame_idx += 1\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"âœ… Cropped video saved: {frames_written} frames written\")\n",
    "        \n",
    "        # Verify output file\n",
    "        if frames_written == 0:\n",
    "            print(\"âš ï¸ Warning: No frames were written to output file!\")\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error cropping video: {e}\")\n",
    "        return False\n",
    "\n",
    "# UPDATED function with bounding box cropping\n",
    "def process_video_with_hsmr(video_path, output_dir, gavd_df=None, use_bbox_crop=True, \n",
    "                          verbose=True, show_output=True):\n",
    "    \"\"\"\n",
    "    Process a single video file using HSMR to extract skeleton parameters.\n",
    "    Optionally crops video using GAVD bounding box data first.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the input video file\n",
    "        output_dir (str): Directory to save the output .npy file\n",
    "        gavd_df (pd.DataFrame): GAVD dataset with bounding box information\n",
    "        use_bbox_crop (bool): Whether to crop video using bounding box data\n",
    "        verbose (bool): Whether to print progress information\n",
    "        show_output (bool): Whether to show real-time command output\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success, output_file_path, error_message)\n",
    "    \"\"\"\n",
    "    video_path = Path(video_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    if not video_path.exists():\n",
    "        return False, None, f\"Video file not found: {video_path}\"\n",
    "    \n",
    "    # Expected output file name (HSMR adds the model name prefix)\n",
    "    expected_output = output_dir / f\"HSMR-{video_path.stem}.npy\"\n",
    "    \n",
    "    # Check if already processed\n",
    "    if expected_output.exists():\n",
    "        if verbose:\n",
    "            print(f\"â­ï¸ Skipping {video_path.name} - already processed\")\n",
    "        return True, expected_output, None\n",
    "    \n",
    "    # Determine which video file to process\n",
    "    video_to_process = video_path\n",
    "    \n",
    "    # Crop video using bounding box if requested and data is available\n",
    "    if use_bbox_crop and gavd_df is not None:\n",
    "        sequence_id = video_path.stem  # Extract sequence ID from filename\n",
    "        sequence_data = get_sequence_bbox_data(sequence_id, gavd_df)\n",
    "        \n",
    "        if sequence_data is not None:\n",
    "            # Create cropped video path\n",
    "            cropped_video_path = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_cropped.mp4\"\n",
    "            \n",
    "            if not cropped_video_path.exists():\n",
    "                if verbose:\n",
    "                    print(f\"âœ‚ï¸ Cropping video using bounding box data...\")\n",
    "                \n",
    "                success = crop_video_with_bbox(\n",
    "                    str(video_path), \n",
    "                    str(cropped_video_path), \n",
    "                    sequence_data\n",
    "                )\n",
    "                \n",
    "                if not success:\n",
    "                    if verbose:\n",
    "                        print(f\"âš ï¸ Cropping failed, using original video\")\n",
    "                else:\n",
    "                    video_to_process = cropped_video_path\n",
    "                    if verbose:\n",
    "                        print(f\"âœ… Using cropped video: {cropped_video_path}\")\n",
    "            else:\n",
    "                video_to_process = cropped_video_path\n",
    "                if verbose:\n",
    "                    print(f\"ğŸ“ Using existing cropped video: {cropped_video_path}\")\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"âš ï¸ No bounding box data found for {sequence_id}, using original video\")\n",
    "    \n",
    "    try:\n",
    "        # Construct the command with CORRECT model path\n",
    "        model_root = \"./HSMR/data_inputs/released_models/HSMR-ViTH-r1d1\"\n",
    "        cmd = [\n",
    "            \"python\", \n",
    "            HSMR_SCRIPT,\n",
    "            \"--input_path\", str(video_to_process),\n",
    "            \"--output_path\", str(output_dir),\n",
    "            \"--model_root\", model_root\n",
    "        ]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ¬ Processing: {video_to_process.name}\")\n",
    "            print(f\"ğŸ’» Command: {' '.join(cmd)}\")\n",
    "            if show_output:\n",
    "                print(\"ğŸ“º Real-time output:\")\n",
    "                print(\"=\" * 80)\n",
    "        \n",
    "        # Run the command with real-time output\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if show_output and verbose:\n",
    "            # Show real-time output\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                bufsize=1,\n",
    "                universal_newlines=True,\n",
    "                cwd=\".\"\n",
    "            )\n",
    "            \n",
    "            # Print output in real-time\n",
    "            output_lines = []\n",
    "            for line in iter(process.stdout.readline, ''):\n",
    "                if line.strip():  # Only print non-empty lines\n",
    "                    print(f\"ğŸ“Ÿ {line.rstrip()}\")\n",
    "                output_lines.append(line)\n",
    "            \n",
    "            process.stdout.close()\n",
    "            return_code = process.wait()\n",
    "            \n",
    "            full_output = ''.join(output_lines)\n",
    "            \n",
    "        else:\n",
    "            # Capture output without showing (for batch processing)\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                cwd=\".\"\n",
    "            )\n",
    "            return_code = result.returncode\n",
    "            full_output = result.stdout\n",
    "            stderr_output = result.stderr\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        if return_code == 0:\n",
    "            if verbose:\n",
    "                if show_output:\n",
    "                    print(\"=\" * 80)\n",
    "                print(f\"âœ… Success! Processed in {end_time - start_time:.2f}s\")\n",
    "                print(f\"ğŸ“„ Output: {expected_output}\")\n",
    "            return True, expected_output, None\n",
    "        else:\n",
    "            if show_output and verbose:\n",
    "                error_msg = f\"Command failed with return code {return_code}\\\\nOutput: {full_output}\"\n",
    "            else:\n",
    "                error_msg = f\"Command failed with return code {return_code}\\\\nSTDOUT: {full_output}\\\\nSTDERR: {stderr_output if 'stderr_output' in locals() else 'N/A'}\"\n",
    "            \n",
    "            if verbose:\n",
    "                if show_output:\n",
    "                    print(\"=\" * 80)\n",
    "                print(f\"âŒ Failed: {error_msg}\")\n",
    "            return False, None, error_msg\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Exception occurred: {str(e)}\"\n",
    "        if verbose:\n",
    "            print(f\"âŒ Exception: {error_msg}\")\n",
    "        return False, None, error_msg\n",
    "\n",
    "# Load the GAVD dataset\n",
    "try:\n",
    "    gavd_dataset = load_gavd_dataset()\n",
    "    print(\"ğŸ”§ UPDATED function with bounding box cropping defined successfully!\")\n",
    "    print(\"ğŸ“ Model path: ./HSMR/data_inputs/released_models/HSMR-ViTH-r1d1\")\n",
    "    print(\"âœ‚ï¸ Bounding box cropping: ENABLED\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Could not load GAVD dataset: {e}\")\n",
    "    print(\"ğŸ”§ Function defined with bounding box cropping DISABLED\")\n",
    "    gavd_dataset = None\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Sample Processing\n",
    "\n",
    "Process a few sample videos to test the pipeline and verify everything works correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¼ Found 1801 video files\n",
      "ğŸ¯ Selected 1 videos for sample processing:\n",
      "  1. cljanb45y00083n6lmh1qhydd.mp4 (0.5 MB)\n",
      "\\n==================================================\n",
      "ğŸš€ Starting sample processing...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all video files\n",
    "video_files = list(Path(GAVD_SEQUENCES_DIR).glob('*.mp4'))\n",
    "print(f\"ğŸ“¼ Found {len(video_files)} video files\")\n",
    "\n",
    "# Select first 3 videos for sample processing\n",
    "sample_videos = video_files[1:2]\n",
    "print(f\"ğŸ¯ Selected {len(sample_videos)} videos for sample processing:\")\n",
    "for i, video in enumerate(sample_videos, 1):\n",
    "    print(f\"  {i}. {video.name} ({video.stat().st_size / (1024*1024):.1f} MB)\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"ğŸš€ Starting sample processing...\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the FIXED cropping function\n",
    "# print(\"ğŸ”„ Testing FIXED bounding box cropping (ignoring GAVD frame numbers)...\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Clean up any existing test files\n",
    "# test_sequence = \"cljanb45y00083n6lmh1qhydd\"\n",
    "# test_files = list(Path(CROPPED_VIDEOS_DIR).glob(f'{test_sequence}*'))\n",
    "# for test_file in test_files:\n",
    "#     test_file.unlink()\n",
    "#     print(f\"ğŸ—‘ï¸ Cleaned up: {test_file.name}\")\n",
    "\n",
    "# # Run the test\n",
    "# test_bbox_cropping(test_sequence)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Test Bounding Box Cropping\n",
    "\n",
    "Let's test the bounding box cropping functionality on a sample video to verify it's working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ Cleaned up: cljanb45y00083n6lmh1qhydd_test_cropped.mp4\n",
      "ğŸ§ª Testing bounding box cropping for sequence: cljanb45y00083n6lmh1qhydd\n",
      "============================================================\n",
      "ğŸ“‹ Sequence Information:\n",
      "  ğŸ“¼ Sequence ID: cljanb45y00083n6lmh1qhydd\n",
      "  ğŸ“Š GAVD frames: 215\n",
      "  ğŸ¯ GAVD frame range: 2532 - 2746\n",
      "  ğŸ¬ Video frames: 214\n",
      "  âš¡ Video FPS: 30\n",
      "  ğŸš¶ Gait pattern: parkinsons\n",
      "  ğŸ“· Camera view: left side\n",
      "\\nğŸ” Frame Mapping Analysis:\n",
      "  ğŸ“Š GAVD sequence length: 215 frames\n",
      "  ğŸ¬ Video length: 214 frames\n",
      "  ğŸ“ Ratio: 1.00 (GAVD/Video)\n",
      "  âš ï¸ GAVD frame range exceeds video length!\n",
      "  ğŸ’¡ Will process all 214 video frames with bounding box data\n",
      "\\nğŸ“ Bounding Box Statistics:\n",
      "  âœ… Valid bboxes: 215/215\n",
      "  ğŸ“ Width range: 247.0 - 291.0 (avg: 268.1)\n",
      "  ğŸ“ Height range: 485.0 - 504.0 (avg: 491.0)\n",
      "  ğŸ¯ Position X: 453.0 - 805.0\n",
      "  ğŸ¯ Position Y: 110.0 - 131.0\n",
      "\\nğŸ“¦ Sample Bounding Boxes:\n",
      "  First frame: top=129.0, left=805.0, width=247.0, height=485.0\n",
      "  Last frame:  top=131.0, left=475.0, width=247.0, height=485.0\n",
      "\\nâœ‚ï¸ Testing Video Cropping:\n",
      "  ğŸ“¥ Input: GAVD-sequences\\cljanb45y00083n6lmh1qhydd.mp4 (0.46 MB)\n",
      "ğŸ¬ Input video: 214 frames at 30 FPS\n",
      "ğŸ“‹ Sequence data: 215 frames\n",
      "ğŸ“ Crop region: (433, 90) to (1072, 636)\n",
      "ğŸ“ Crop size: 639x546\n",
      "ğŸ¯ GAVD frame range: 2532 to 2746\n",
      "ğŸ¯ Video frame range: 0 to 213\n",
      "ğŸ“¦ Using 215 bounding boxes for cropping\n",
      "âœ… Cropped video saved: 214 frames written\n",
      "  ğŸ“¤ Output: GAVD-cropped-sequences\\cljanb45y00083n6lmh1qhydd_test_cropped.mp4 (0.80 MB)\n",
      "  ğŸ“Š Size reduction: -74.0% (ratio: 1.740)\n",
      "  âœ… Cropping test SUCCESSFUL!\n",
      "  ğŸ“Š Output video: 214 frames\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test bounding box cropping functionality with frame analysis\n",
    "def test_bbox_cropping(sequence_id=\"cljanb45y00083n6lmh1qhydd\"):\n",
    "    \"\"\"Test the bounding box cropping functionality on a specific sequence.\"\"\"\n",
    "    \n",
    "    if gavd_dataset is None:\n",
    "        print(\"âŒ GAVD dataset not loaded. Cannot test bounding box cropping.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ§ª Testing bounding box cropping for sequence: {sequence_id}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get sequence data\n",
    "    sequence_data = get_sequence_bbox_data(sequence_id, gavd_dataset)\n",
    "    \n",
    "    if sequence_data is None:\n",
    "        print(f\"âŒ No data found for sequence: {sequence_id}\")\n",
    "        return\n",
    "    \n",
    "    # Check video file\n",
    "    input_video = Path(GAVD_SEQUENCES_DIR) / f\"{sequence_id}.mp4\"\n",
    "    if not input_video.exists():\n",
    "        print(f\"âŒ Input video not found: {input_video}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties for comparison\n",
    "    cap = cv2.VideoCapture(str(input_video))\n",
    "    if cap.isOpened():\n",
    "        video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        video_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        cap.release()\n",
    "    else:\n",
    "        print(f\"âŒ Cannot open video for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Display sequence information\n",
    "    print(f\"ğŸ“‹ Sequence Information:\")\n",
    "    print(f\"  ğŸ“¼ Sequence ID: {sequence_id}\")\n",
    "    print(f\"  ğŸ“Š GAVD frames: {len(sequence_data)}\")\n",
    "    print(f\"  ğŸ¯ GAVD frame range: {sequence_data['frame_num'].min()} - {sequence_data['frame_num'].max()}\")\n",
    "    print(f\"  ğŸ¬ Video frames: {video_frames}\")\n",
    "    print(f\"  âš¡ Video FPS: {video_fps}\")\n",
    "    \n",
    "    if 'gait_pat' in sequence_data.columns:\n",
    "        print(f\"  ğŸš¶ Gait pattern: {sequence_data['gait_pat'].iloc[0]}\")\n",
    "    if 'cam_view' in sequence_data.columns:\n",
    "        print(f\"  ğŸ“· Camera view: {sequence_data['cam_view'].iloc[0]}\")\n",
    "    \n",
    "    # Frame mapping analysis\n",
    "    gavd_min = sequence_data['frame_num'].min()\n",
    "    gavd_max = sequence_data['frame_num'].max()\n",
    "    gavd_range = gavd_max - gavd_min + 1\n",
    "    \n",
    "    print(f\"\\\\nğŸ” Frame Mapping Analysis:\")\n",
    "    print(f\"  ğŸ“Š GAVD sequence length: {gavd_range} frames\")\n",
    "    print(f\"  ğŸ¬ Video length: {video_frames} frames\")\n",
    "    print(f\"  ğŸ“ Ratio: {gavd_range/video_frames:.2f} (GAVD/Video)\")\n",
    "    \n",
    "    if gavd_range > video_frames:\n",
    "        print(f\"  âš ï¸ GAVD frame range exceeds video length!\")\n",
    "        print(f\"  ğŸ’¡ Will process all {video_frames} video frames with bounding box data\")\n",
    "    \n",
    "    # Display bounding box statistics\n",
    "    valid_bboxes = [bbox for bbox in sequence_data['bbox_parsed'] if bbox is not None]\n",
    "    \n",
    "    if valid_bboxes:\n",
    "        print(f\"\\\\nğŸ“ Bounding Box Statistics:\")\n",
    "        print(f\"  âœ… Valid bboxes: {len(valid_bboxes)}/{len(sequence_data)}\")\n",
    "        \n",
    "        all_tops = [bbox['top'] for bbox in valid_bboxes]\n",
    "        all_lefts = [bbox['left'] for bbox in valid_bboxes]\n",
    "        all_widths = [bbox['width'] for bbox in valid_bboxes]\n",
    "        all_heights = [bbox['height'] for bbox in valid_bboxes]\n",
    "        \n",
    "        print(f\"  ğŸ“ Width range: {min(all_widths):.1f} - {max(all_widths):.1f} (avg: {np.mean(all_widths):.1f})\")\n",
    "        print(f\"  ğŸ“ Height range: {min(all_heights):.1f} - {max(all_heights):.1f} (avg: {np.mean(all_heights):.1f})\")\n",
    "        print(f\"  ğŸ¯ Position X: {min(all_lefts):.1f} - {max(all_lefts):.1f}\")\n",
    "        print(f\"  ğŸ¯ Position Y: {min(all_tops):.1f} - {max(all_tops):.1f}\")\n",
    "        \n",
    "        # Show first and last bbox\n",
    "        print(f\"\\\\nğŸ“¦ Sample Bounding Boxes:\")\n",
    "        first_bbox = valid_bboxes[0]\n",
    "        last_bbox = valid_bboxes[-1]\n",
    "        \n",
    "        print(f\"  First frame: top={first_bbox['top']}, left={first_bbox['left']}, \"\n",
    "              f\"width={first_bbox['width']}, height={first_bbox['height']}\")\n",
    "        print(f\"  Last frame:  top={last_bbox['top']}, left={last_bbox['left']}, \"\n",
    "              f\"width={last_bbox['width']}, height={last_bbox['height']}\")\n",
    "    else:\n",
    "        print(f\"âŒ No valid bounding boxes found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\\\nâœ‚ï¸ Testing Video Cropping:\")\n",
    "    print(f\"  ğŸ“¥ Input: {input_video} ({input_video.stat().st_size / (1024*1024):.2f} MB)\")\n",
    "    \n",
    "    # Clean up any existing test files\n",
    "    test_output = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_test_cropped.mp4\"\n",
    "    if test_output.exists():\n",
    "        test_output.unlink()\n",
    "        print(f\"  ğŸ—‘ï¸ Removed existing test file\")\n",
    "    \n",
    "    # Perform cropping\n",
    "    success = crop_video_with_bbox(str(input_video), str(test_output), sequence_data)\n",
    "    \n",
    "    if success and test_output.exists():\n",
    "        output_size_mb = test_output.stat().st_size / (1024*1024)\n",
    "        input_size_mb = input_video.stat().st_size / (1024*1024)\n",
    "        compression_ratio = output_size_mb / input_size_mb if input_size_mb > 0 else 0\n",
    "        \n",
    "        print(f\"  ğŸ“¤ Output: {test_output} ({output_size_mb:.2f} MB)\")\n",
    "        print(f\"  ğŸ“Š Size reduction: {(1-compression_ratio)*100:.1f}% (ratio: {compression_ratio:.3f})\")\n",
    "        \n",
    "        if output_size_mb > 0.01:  # Check if file has reasonable size\n",
    "            print(f\"  âœ… Cropping test SUCCESSFUL!\")\n",
    "            \n",
    "            # Verify the output video can be opened\n",
    "            test_cap = cv2.VideoCapture(str(test_output))\n",
    "            if test_cap.isOpened():\n",
    "                test_frames = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                test_cap.release()\n",
    "                print(f\"  ğŸ“Š Output video: {test_frames} frames\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ Output video cannot be opened!\")\n",
    "        else:\n",
    "            print(f\"  âŒ Output file too small - cropping may have failed!\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"  âŒ Cropping test FAILED!\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Clean up any existing test files first\n",
    "existing_test_files = list(Path(CROPPED_VIDEOS_DIR).glob('*test_cropped.mp4'))\n",
    "for test_file in existing_test_files:\n",
    "    test_file.unlink()\n",
    "    print(f\"ğŸ—‘ï¸ Cleaned up: {test_file.name}\")\n",
    "\n",
    "# Run the test\n",
    "test_bbox_cropping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process sample videos with FIXED bounding box cropping\n",
    "# print(\"ğŸš€ Running sample processing with FIXED cropping...\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# sample_results = []\n",
    "\n",
    "# for i, video_path in enumerate(sample_videos, 1):\n",
    "#     print(f\"\\\\nğŸ“¹ Processing sample {i}/{len(sample_videos)}: {video_path.name}\")\n",
    "#     print(\"-\" * 60)\n",
    "    \n",
    "#     # Check if we have bounding box data for this sequence\n",
    "#     sequence_id = video_path.stem\n",
    "#     if gavd_dataset is not None:\n",
    "#         sequence_data = get_sequence_bbox_data(sequence_id, gavd_dataset)\n",
    "#         if sequence_data is not None:\n",
    "#             print(f\"ğŸ“‹ Found {len(sequence_data)} bounding box annotations\")\n",
    "#             print(f\"ğŸ“Š GAVD frame range: {sequence_data['frame_num'].min()} - {sequence_data['frame_num'].max()}\")\n",
    "#             print(f\"ğŸ’¡ Will ignore frame numbers and use bbox data for consistent cropping\")\n",
    "            \n",
    "#             # Show sample bounding box\n",
    "#             sample_bbox = sequence_data.iloc[0]['bbox_parsed']\n",
    "#             if sample_bbox:\n",
    "#                 print(f\"ğŸ“ Sample bbox: top={sample_bbox['top']}, left={sample_bbox['left']}, \"\n",
    "#                       f\"width={sample_bbox['width']}, height={sample_bbox['height']}\")\n",
    "#         else:\n",
    "#             print(\"âš ï¸ No bounding box data found for this sequence\")\n",
    "    \n",
    "#     # Clean any existing cropped video for this sequence to force re-cropping\n",
    "#     cropped_path = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_cropped.mp4\"\n",
    "#     if cropped_path.exists():\n",
    "#         cropped_path.unlink()\n",
    "#         print(f\"ğŸ—‘ï¸ Removed existing cropped video to test new cropping\")\n",
    "    \n",
    "#     success, output_path, error = process_video_with_hsmr(\n",
    "#         video_path=video_path,\n",
    "#         output_dir=OUTPUT_DIR,\n",
    "#         gavd_df=gavd_dataset,  # Pass the GAVD dataset\n",
    "#         use_bbox_crop=True,    # Enable bounding box cropping\n",
    "#         verbose=True,\n",
    "#         show_output=True  # Don't show HSMR output for cleaner test\n",
    "#     )\n",
    "    \n",
    "#     sample_results.append({\n",
    "#         'video': video_path.name,\n",
    "#         'success': success,\n",
    "#         'output': output_path,\n",
    "#         'error': error\n",
    "#     })\n",
    "    \n",
    "#     if success:\n",
    "#         print(f\"âœ… Sample {i} completed successfully!\")\n",
    "#         if output_path and output_path.exists():\n",
    "#             print(f\"ğŸ“Š Output file size: {output_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "#     else:\n",
    "#         print(f\"âŒ Sample {i} failed: {error}\")\n",
    "    \n",
    "#     print(\"-\" * 60)\n",
    "\n",
    "# # Summary\n",
    "# print(f\"\\\\nğŸ“‹ Sample Processing Summary:\")\n",
    "# print(f\"âœ… Successful: {sum(1 for r in sample_results if r['success'])}\")\n",
    "# print(f\"âŒ Failed: {sum(1 for r in sample_results if not r['success'])}\")\n",
    "\n",
    "# for result in sample_results:\n",
    "#     status = \"âœ…\" if result['success'] else \"âŒ\"\n",
    "#     print(f\"  {status} {result['video']}\")\n",
    "#     if not result['success']:\n",
    "#         print(f\"    Error: {result['error'][:100]}...\")  # Truncate long errors\n",
    "\n",
    "# # Show cropped videos info with detailed analysis\n",
    "# cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "# if cropped_videos:\n",
    "#     print(f\"\\\\nâœ‚ï¸ Generated {len(cropped_videos)} cropped videos:\")\n",
    "#     for cropped_video in cropped_videos:\n",
    "#         size_mb = cropped_video.stat().st_size / (1024*1024)\n",
    "#         print(f\"  ğŸ“„ {cropped_video.name} ({size_mb:.2f} MB)\")\n",
    "        \n",
    "#         # Verify the cropped video can be opened\n",
    "#         try:\n",
    "#             test_cap = cv2.VideoCapture(str(cropped_video))\n",
    "#             if test_cap.isOpened():\n",
    "#                 frames = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#                 width = int(test_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#                 height = int(test_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#                 test_cap.release()\n",
    "#                 print(f\"    âœ… Playable: {frames} frames, {width}x{height}\")\n",
    "#             else:\n",
    "#                 print(f\"    âŒ Cannot open video file\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"    âŒ Error checking video: {e}\")\n",
    "\n",
    "# print(\"\\\\nğŸ‰ FIXED cropping test complete!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process all videos in the GAVD-sequences directory. This cell will process all remaining videos with progress tracking and error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Batch processing function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import gc  # For garbage collection\n",
    "\n",
    "# Skip list management\n",
    "SKIP_LIST_FILE = \"failed_videos_skiplist.txt\"\n",
    "\n",
    "def load_skip_list():\n",
    "    \"\"\"Load the list of videos to skip from file.\"\"\"\n",
    "    skip_list = set()\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    if skip_file.exists():\n",
    "        with open(skip_file, 'r') as f:\n",
    "            skip_list = set(line.strip() for line in f if line.strip())\n",
    "        print(f\"ğŸ“‹ Loaded skip list: {len(skip_list)} videos to skip\")\n",
    "    return skip_list\n",
    "\n",
    "def add_to_skip_list(video_name, error_msg):\n",
    "    \"\"\"Add a video to the skip list.\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    with open(skip_file, 'a') as f:\n",
    "        f.write(f\"{video_name}\\n\")\n",
    "    \n",
    "    # Also log the detailed error\n",
    "    error_log_file = Path(\"failed_videos_errors.log\")\n",
    "    with open(error_log_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(f\"\\n{'='*80}\\n\")\n",
    "        f.write(f\"Video: {video_name}\\n\")\n",
    "        f.write(f\"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Error: {error_msg}\\n\")\n",
    "        f.write(f\"{'='*80}\\n\")\n",
    "\n",
    "def batch_process_videos(video_dir, output_dir, max_videos=None, skip_existing=True, \n",
    "                        use_bbox_crop=True, gavd_df=None, auto_skip_failed=True):\n",
    "    \"\"\"\n",
    "    Batch process all videos in a directory with optional bounding box cropping.\n",
    "    \n",
    "    Args:\n",
    "        video_dir (str): Directory containing input videos\n",
    "        output_dir (str): Directory to save output files\n",
    "        max_videos (int, optional): Maximum number of videos to process (for testing)\n",
    "        skip_existing (bool): Whether to skip already processed videos\n",
    "        use_bbox_crop (bool): Whether to use bounding box cropping\n",
    "        gavd_df (pd.DataFrame): GAVD dataset with bounding box information\n",
    "        auto_skip_failed (bool): Whether to automatically skip previously failed videos\n",
    "    \n",
    "    Returns:\n",
    "        dict: Processing statistics and results\n",
    "    \"\"\"\n",
    "    video_files = list(Path(video_dir).glob('*.mp4'))\n",
    "    \n",
    "    # Load skip list\n",
    "    skip_list = load_skip_list() if auto_skip_failed else set()\n",
    "    \n",
    "    # Filter out videos in skip list\n",
    "    if skip_list:\n",
    "        original_count = len(video_files)\n",
    "        video_files = [v for v in video_files if v.name not in skip_list]\n",
    "        skipped_count = original_count - len(video_files)\n",
    "        print(f\"â­ï¸ Skipping {skipped_count} videos from previous failures\")\n",
    "    \n",
    "    if max_videos:\n",
    "        video_files = video_files[:max_videos]\n",
    "    \n",
    "    print(f\"ğŸ¬ Starting batch processing of {len(video_files)} videos\")\n",
    "    print(f\"ğŸ“ Input: {video_dir}\")\n",
    "    print(f\"ğŸ“ Output: {output_dir}\")\n",
    "    print(f\"â­ï¸ Skip existing: {skip_existing}\")\n",
    "    print(f\"âš ï¸ Auto-skip failed: {auto_skip_failed}\")\n",
    "    print(f\"âœ‚ï¸ Bounding box cropping: {'ENABLED' if use_bbox_crop and gavd_df is not None else 'DISABLED'}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process with progress bar\n",
    "    for i, video_path in enumerate(tqdm(video_files, desc=\"Processing videos\"), 1):\n",
    "        try:\n",
    "            success, output_path, error = process_video_with_hsmr(\n",
    "                video_path=video_path,\n",
    "                output_dir=output_dir,\n",
    "                gavd_df=gavd_df,  # Pass GAVD dataset\n",
    "                use_bbox_crop=use_bbox_crop,  # Enable/disable bbox cropping\n",
    "                verbose=False,  # Reduce verbosity for batch processing\n",
    "                show_output=True  # Don't show output for batch processing\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'video': video_path.name,\n",
    "                'success': success,\n",
    "                'output': output_path,\n",
    "                'error': error,\n",
    "                'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "            \n",
    "            # Handle failed videos\n",
    "            if not success:\n",
    "                # Show full error message\n",
    "                print(f\"\\nâŒ [{i:4d}/{len(video_files):4d}] {video_path.name}\")\n",
    "                print(f\"ğŸ“„ FULL ERROR MESSAGE:\")\n",
    "                print(\"=\" * 60)\n",
    "                print(error)\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                # Add to skip list for future runs\n",
    "                add_to_skip_list(video_path.name, error)\n",
    "                print(f\"ğŸ“ Added {video_path.name} to skip list\")\n",
    "            \n",
    "            # Print periodic success updates\n",
    "            elif i % 10 == 0:\n",
    "                print(f\"âœ… [{i:4d}/{len(video_files):4d}] {video_path.name}\")\n",
    "            \n",
    "            # Garbage collection every 20 videos to prevent memory buildup\n",
    "            if i % 20 == 0:\n",
    "                gc.collect()\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Unexpected exception during processing: {str(e)}\"\n",
    "            print(f\"\\nğŸ’¥ [{i:4d}/{len(video_files):4d}] {video_path.name}\")\n",
    "            print(f\"ğŸ“„ EXCEPTION:\")\n",
    "            print(\"=\" * 60)\n",
    "            print(error_msg)\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            results.append({\n",
    "                'video': video_path.name,\n",
    "                'success': False,\n",
    "                'output': None,\n",
    "                'error': error_msg,\n",
    "                'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "            \n",
    "            # Add to skip list\n",
    "            add_to_skip_list(video_path.name, error_msg)\n",
    "            print(f\"ğŸ“ Added {video_path.name} to skip list\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = len(results) - successful\n",
    "    total_size_mb = sum(r['size_mb'] for r in results)\n",
    "    avg_time_per_video = total_time / len(results) if results else 0\n",
    "    \n",
    "    # Count cropped videos\n",
    "    cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "    \n",
    "    # Final garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    stats = {\n",
    "        'total_videos': len(results),\n",
    "        'successful': successful,\n",
    "        'failed': failed,\n",
    "        'total_time_seconds': total_time,\n",
    "        'avg_time_per_video': avg_time_per_video,\n",
    "        'total_size_mb': total_size_mb,\n",
    "        'cropped_videos': len(cropped_videos),\n",
    "        'skipped_from_list': len(skip_list) if skip_list else 0,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Test function definition\n",
    "print(\"ğŸ”§ Batch processing function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Skip List Status:\n",
      "==================================================\n",
      "ğŸ“‹ Loaded skip list: 82 videos to skip\n",
      "ğŸ“„ Skip list file: failed_videos_skiplist.txt\n",
      "ğŸš« Videos to skip: 82\n",
      "ğŸ“ Recent entries (last 10):\n",
      "  - cljap5o8u004r3n6llsoy3aww.mp4\n",
      "  - cljapao5600503n6lhrbr4zii.mp4\n",
      "  - cljapbtwe00543n6lsdbwbhhi.mp4\n",
      "  - cljaotzi6002g3n6ljofm5j6d.mp4\n",
      "  - cljaouueo002k3n6l57zl7081.mp4\n",
      "  - cljaqc7jf00943n6l9cmdtsmn.mp4\n",
      "  - cljaqdekt00983n6ldn9m222j.mp4\n",
      "  - cljaqocwq00a23n6lj8kgw100.mp4\n",
      "  - cljaqqdar00aa3n6lblt5iei7.mp4\n",
      "  - cljaqrnsq00ae3n6lo53132n5.mp4\n",
      "\n",
      "ğŸ“„ Error log file: failed_videos_errors.log (0.38 MB)\n",
      "ğŸ’¡ Check this file for detailed error messages\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Skip List Management Utilities\n",
    "def show_skip_list_status():\n",
    "    \"\"\"Show current skip list status and recent failures.\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    error_log_file = Path(\"failed_videos_errors.log\")\n",
    "    \n",
    "    print(\"ğŸ“‹ Skip List Status:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if skip_file.exists():\n",
    "        skip_list = load_skip_list()\n",
    "        print(f\"ğŸ“„ Skip list file: {SKIP_LIST_FILE}\")\n",
    "        print(f\"ğŸš« Videos to skip: {len(skip_list)}\")\n",
    "        \n",
    "        if len(skip_list) > 0:\n",
    "            print(f\"ğŸ“ Recent entries (last 10):\")\n",
    "            with open(skip_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines[-10:]:\n",
    "                    print(f\"  - {line.strip()}\")\n",
    "    else:\n",
    "        print(f\"ğŸ“„ No skip list found ({SKIP_LIST_FILE})\")\n",
    "    \n",
    "    print()\n",
    "    if error_log_file.exists():\n",
    "        size_mb = error_log_file.stat().st_size / (1024*1024)\n",
    "        print(f\"ğŸ“„ Error log file: failed_videos_errors.log ({size_mb:.2f} MB)\")\n",
    "        print(f\"ğŸ’¡ Check this file for detailed error messages\")\n",
    "    else:\n",
    "        print(f\"ğŸ“„ No error log found\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def clear_skip_list():\n",
    "    \"\"\"Clear the skip list (use with caution!).\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    if skip_file.exists():\n",
    "        skip_file.unlink()\n",
    "        print(f\"ğŸ—‘ï¸ Cleared skip list: {SKIP_LIST_FILE}\")\n",
    "    else:\n",
    "        print(f\"ğŸ“„ No skip list to clear\")\n",
    "\n",
    "def remove_from_skip_list(video_names):\n",
    "    \"\"\"Remove specific videos from skip list.\"\"\"\n",
    "    skip_file = Path(SKIP_LIST_FILE)\n",
    "    if not skip_file.exists():\n",
    "        print(f\"ğŸ“„ No skip list found\")\n",
    "        return\n",
    "    \n",
    "    # Read current skip list\n",
    "    with open(skip_file, 'r') as f:\n",
    "        current_list = set(line.strip() for line in f if line.strip())\n",
    "    \n",
    "    # Remove specified videos\n",
    "    if isinstance(video_names, str):\n",
    "        video_names = [video_names]\n",
    "    \n",
    "    removed_count = 0\n",
    "    for video_name in video_names:\n",
    "        if video_name in current_list:\n",
    "            current_list.remove(video_name)\n",
    "            removed_count += 1\n",
    "            print(f\"âœ… Removed {video_name} from skip list\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {video_name} not found in skip list\")\n",
    "    \n",
    "    # Write back the updated list\n",
    "    if removed_count > 0:\n",
    "        with open(skip_file, 'w') as f:\n",
    "            for video_name in sorted(current_list):\n",
    "                f.write(f\"{video_name}\\n\")\n",
    "        print(f\"ğŸ“ Updated skip list: removed {removed_count} videos\")\n",
    "\n",
    "# Show current status\n",
    "show_skip_list_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Loaded skip list: 82 videos to skip\n",
      "â­ï¸ Skipping 82 videos from previous failures\n",
      "ğŸ¬ Starting batch processing of 1719 videos\n",
      "ğŸ“ Input: ./GAVD-sequences\n",
      "ğŸ“ Output: ./GAVD-hsmr-params\n",
      "â­ï¸ Skip existing: True\n",
      "âš ï¸ Auto-skip failed: True\n",
      "âœ‚ï¸ Bounding box cropping: ENABLED\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 1/1719 [02:50<81:30:38, 170.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âŒ [   1/1719] cljaoyz1c003c3n6l84cbjwg9.mp4\n",
      "ğŸ“„ FULL ERROR MESSAGE:\n",
      "============================================================\n",
      "Command failed with return code 3221225477\\nSTDOUT: Found GAVD-cropped-sequences\\cljaoyz1c003c3n6l84cbjwg9_cropped.mp4 is a file. It will be regarded as a video file.\n",
      "\\nSTDERR: [\u001b[36m07/28 13:40:27\u001b[0m][\u001b[32mINFO\u001b[0m] ğŸšš Loading inputs from: GAVD-cropped-sequences\\cljaoyz1c003c3n6l84cbjwg9_cropped.mp4, regarded as <video>.\u001b[0m\n",
      "\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 3961.57it/s]\n",
      "[\u001b[36m07/28 13:40:27\u001b[0m][\u001b[32mINFO\u001b[0m] ğŸ“¦ Totally 111 images are loaded.\u001b[0m\n",
      "[\u001b[36m07/28 13:40:27\u001b[0m][\u001b[32mINFO\u001b[0m] ğŸ§± Building detector.\u001b[0m\n",
      "c:\\Users\\1nkas-Strix-4090-ll\\miniconda3\\envs\\hsmr\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "[\u001b[36m07/28 13:40:30\u001b[0m][\u001b[32mINFO\u001b[0m] [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692/model_final_f05665.pkl ...\u001b[0m\n",
      "[\u001b[36m07/28 13:40:30\u001b[0m][\u001b[32mINFO\u001b[0m] URL https://dl.fbaipublicfiles.com/detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692/model_final_f05665.pkl cached in C:\\Users\\1nkas-Strix-4090-ll/.torch/iopath_cache\\detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692\\model_final_f05665.pkl\u001b[0m\n",
      "[\u001b[36m07/28 13:40:30\u001b[0m][\u001b[32mINFO\u001b[0m] [Checkpointer] Loading from C:\\Users\\1nkas-Strix-4090-ll/.torch/iopath_cache\\detectron2/ViTDet/COCO/cascade_mask_rcnn_vitdet_h/f328730692\\model_final_f05665.pkl ...\u001b[0m\n",
      "[\u001b[36m07/28 13:40:31\u001b[0m][\u001b[32mINFO\u001b[0m] Reading a file from 'Detectron2 ViTDet Model Zoo'\u001b[0m\n",
      "[\u001b[36m07/28 13:40:31\u001b[0m][\u001b[32mINFO\u001b[0m] [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=1024)]\u001b[0m\n",
      "[\u001b[36m07/28 13:40:31\u001b[0m][\u001b[32mINFO\u001b[0m] ğŸ–¼ï¸ Detecting...\u001b[0m\n",
      "\n",
      "Batch Detection:   0%|          | 0/111 [00:00<?, ?it/s]c:\\Users\\1nkas-Strix-4090-ll\\miniconda3\\envs\\hsmr\\lib\\site-packages\\torch\\functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3596.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "Batch Detection:   9%|â–‰         | 10/111 [00:15<02:39,  1.58s/it]\n",
      "Batch Detection:  18%|â–ˆâ–Š        | 20/111 [00:30<02:17,  1.51s/it]\n",
      "Batch Detection:  27%|â–ˆâ–ˆâ–‹       | 30/111 [00:44<01:59,  1.48s/it]\n",
      "Batch Detection:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/111 [00:59<01:43,  1.46s/it]\n",
      "Batch Detection:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 50/111 [01:13<01:28,  1.45s/it]\n",
      "Batch Detection:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/111 [01:27<01:13,  1.44s/it]\n",
      "Batch Detection:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/111 [01:42<00:59,  1.44s/it]\n",
      "Batch Detection:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 80/111 [01:56<00:44,  1.44s/it]\n",
      "Batch Detection:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 90/111 [02:10<00:30,  1.44s/it]\n",
      "Batch Detection:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 100/111 [02:25<00:15,  1.43s/it]\n",
      "Batch Detection:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 110/111 [02:39<00:01,  1.43s/it]\n",
      "Batch Detection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [02:39<00:00,  1.39s/it]\n",
      "Batch Detection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [02:39<00:00,  1.44s/it]\n",
      "\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:00<00:00, 1463.34it/s]\n",
      "[\u001b[36m07/28 13:43:12\u001b[0m][\u001b[32mINFO\u001b[0m] ğŸ” Totally 111 human instances are detected.\u001b[0m\n",
      "[\u001b[36m07/28 13:43:12\u001b[0m][\u001b[32mINFO\u001b[0m] ğŸ§± Building recovery pipeline.\u001b[0m\n",
      "\n",
      "============================================================\n",
      "ğŸ“ Added cljaoyz1c003c3n6l84cbjwg9.mp4 to skip list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 8/1719 [42:34<274:44:35, 578.07s/it]"
     ]
    }
   ],
   "source": [
    "# Run batch processing with bounding box cropping\n",
    "# WARNING: This will process ALL videos in GAVD-sequences directory\n",
    "# Set max_videos to a small number for testing, or None to process all\n",
    "\n",
    "# For testing: process only 10 videos with bounding box cropping\n",
    "# batch_stats = batch_process_videos(GAVD_SEQUENCES_DIR, OUTPUT_DIR, max_videos=10, \n",
    "#                                  use_bbox_crop=True, gavd_df=gavd_dataset)\n",
    "\n",
    "# For full processing: remove max_videos parameter or set to None\n",
    "batch_stats = batch_process_videos(GAVD_SEQUENCES_DIR, OUTPUT_DIR, max_videos=None,\n",
    "                                 use_bbox_crop=True, gavd_df=gavd_dataset, \n",
    "                                 auto_skip_failed=True)  # Enable auto-skip of failed videos\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“¼ Total videos processed: {batch_stats['total_videos']}\")\n",
    "print(f\"âœ… Successful: {batch_stats['successful']}\")\n",
    "print(f\"âŒ Failed: {batch_stats['failed']}\")\n",
    "print(f\"â­ï¸ Skipped from skip list: {batch_stats.get('skipped_from_list', 0)}\")\n",
    "print(f\"âœ‚ï¸ Cropped videos generated: {batch_stats.get('cropped_videos', 0)}\")\n",
    "print(f\"â±ï¸ Total time: {batch_stats['total_time_seconds']:.2f} seconds ({batch_stats['total_time_seconds']/60:.1f} minutes)\")\n",
    "print(f\"âš¡ Average time per video: {batch_stats['avg_time_per_video']:.2f} seconds\")\n",
    "print(f\"ğŸ’¾ Total input size: {batch_stats['total_size_mb']:.1f} MB\")\n",
    "\n",
    "if batch_stats['failed'] > 0:\n",
    "    print(f\"\\\\nâŒ Failed videos:\")\n",
    "    failed_videos = [r for r in batch_stats['results'] if not r['success']]\n",
    "    for failed in failed_videos[:10]:  # Show first 10 failures\n",
    "        print(f\"  - {failed['video']}: {failed['error'][:80]}...\")\n",
    "    if len(failed_videos) > 10:\n",
    "        print(f\"  ... and {len(failed_videos) - 10} more failures\")\n",
    "\n",
    "print(f\"\\\\nğŸ“ Output files saved to: {OUTPUT_DIR}\")\n",
    "output_files = list(Path(OUTPUT_DIR).glob('*.npy'))\n",
    "print(f\"ğŸ“„ Generated {len(output_files)} .npy files\")\n",
    "\n",
    "print(f\"\\\\nğŸ“ Cropped videos saved to: {CROPPED_VIDEOS_DIR}\")\n",
    "cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "if cropped_videos:\n",
    "    total_cropped_size = sum(v.stat().st_size for v in cropped_videos) / (1024*1024)\n",
    "    print(f\"âœ‚ï¸ Generated {len(cropped_videos)} cropped videos ({total_cropped_size:.1f} MB total)\")\n",
    "else:\n",
    "    print(\"âœ‚ï¸ No cropped videos generated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Data Inspection\n",
    "\n",
    "Inspect the generated skeleton parameter files to understand the data structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Inspecting: HSMR-cljan9b4p00043n6ligceanyp.npy\n",
      "ğŸ“Š File size: 0.19 MB\n",
      "\\nğŸ“‹ Data structure:\n",
      "  Type: <class 'numpy.ndarray'>\n",
      "  Shape: (511,)\n",
      "  Dtype: object\n",
      "\\nğŸ¬ Video has 511 frames\n",
      "\\nğŸ“¦ First frame keys: ['patch_cam_t', 'poses', 'betas', 'bbx_cs']\n",
      "  patch_cam_t: shape=(1, 3), dtype=float32\n",
      "  poses: shape=(1, 46), dtype=float32\n",
      "  betas: shape=(1, 10), dtype=float32\n",
      "  bbx_cs: <class 'list'> - [array([268.77588, 372.10785, 497.57043], dtype=float32)]\n",
      "\\nğŸ¤¸ Pose parameters:\n",
      "  Shape: (1, 46)\n",
      "  Min/Max: -1.031 / 2.851\n",
      "  Mean: 0.119\n",
      "\\nğŸ‘¤ Shape parameters (betas):\n",
      "  Shape: (1, 10)\n",
      "  Min/Max: -0.093 / 0.210\n",
      "\\nğŸ“· Camera translation:\n",
      "  Shape: (1, 3)\n",
      "  Values: [[-0.07694656  0.06684598 32.80605   ]]\n",
      "\\nâœ… Successfully inspected HSMR-cljan9b4p00043n6ligceanyp.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find and inspect a sample output file\n",
    "output_files = list(Path(OUTPUT_DIR).glob('*.npy'))\n",
    "\n",
    "if output_files:\n",
    "    # Load the first available output file\n",
    "    sample_file = output_files[0]\n",
    "    print(f\"ğŸ” Inspecting: {sample_file.name}\")\n",
    "    print(f\"ğŸ“Š File size: {sample_file.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Load the data\n",
    "        data = np.load(sample_file, allow_pickle=True)\n",
    "        print(f\"\\\\nğŸ“‹ Data structure:\")\n",
    "        print(f\"  Type: {type(data)}\")\n",
    "        \n",
    "        if isinstance(data, np.ndarray):\n",
    "            print(f\"  Shape: {data.shape}\")\n",
    "            print(f\"  Dtype: {data.dtype}\")\n",
    "            \n",
    "            # If it's an array of dictionaries (typical HSMR output)\n",
    "            if data.dtype == object and len(data) > 0:\n",
    "                print(f\"\\\\nğŸ¬ Video has {len(data)} frames\")\n",
    "                \n",
    "                # Inspect first frame\n",
    "                first_frame = data[0]\n",
    "                if isinstance(first_frame, dict):\n",
    "                    print(f\"\\\\nğŸ“¦ First frame keys: {list(first_frame.keys())}\")\n",
    "                    \n",
    "                    for key, value in first_frame.items():\n",
    "                        if isinstance(value, np.ndarray):\n",
    "                            print(f\"  {key}: shape={value.shape}, dtype={value.dtype}\")\n",
    "                        else:\n",
    "                            print(f\"  {key}: {type(value)} - {value}\")\n",
    "                    \n",
    "                    # Show some specific parameter details\n",
    "                    if 'poses' in first_frame:\n",
    "                        poses = first_frame['poses']\n",
    "                        print(f\"\\\\nğŸ¤¸ Pose parameters:\")\n",
    "                        print(f\"  Shape: {poses.shape}\")\n",
    "                        print(f\"  Min/Max: {poses.min():.3f} / {poses.max():.3f}\")\n",
    "                        print(f\"  Mean: {poses.mean():.3f}\")\n",
    "                    \n",
    "                    if 'betas' in first_frame:\n",
    "                        betas = first_frame['betas']\n",
    "                        print(f\"\\\\nğŸ‘¤ Shape parameters (betas):\")\n",
    "                        print(f\"  Shape: {betas.shape}\")\n",
    "                        print(f\"  Min/Max: {betas.min():.3f} / {betas.max():.3f}\")\n",
    "                    \n",
    "                    if 'patch_cam_t' in first_frame:\n",
    "                        cam_t = first_frame['patch_cam_t']\n",
    "                        print(f\"\\\\nğŸ“· Camera translation:\")\n",
    "                        print(f\"  Shape: {cam_t.shape}\")\n",
    "                        print(f\"  Values: {cam_t}\")\n",
    "        \n",
    "        print(f\"\\\\nâœ… Successfully inspected {sample_file.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No output files found. Run the processing cells first.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Batch Video Cropping Only\n",
    "\n",
    "Generate cropped videos for all sequences using bounding box data without running HSMR processing. This is useful for pre-processing all videos or creating a cropped dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Per-frame dynamic cropping function defined successfully!\n",
      "âœ‚ï¸ Uses exact per-frame bbox data from GAVD dataset\n"
     ]
    }
   ],
   "source": [
    "# CORRECTED: Per-frame dynamic cropping function using GAVD bbox data\n",
    "def crop_video_with_bbox_per_frame(input_video_path: str, output_video_path: str, \n",
    "                                  sequence_data: pd.DataFrame, padding: int = 20, \n",
    "                                  show_frame_details: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Crop video using per-frame bounding box data from GAVD dataset.\n",
    "    Each frame uses its corresponding bounding box for cropping.\n",
    "    \n",
    "    Args:\n",
    "        input_video_path (str): Path to input video\n",
    "        output_video_path (str): Path to save cropped video\n",
    "        sequence_data (pd.DataFrame): Sequence data with bounding boxes\n",
    "        padding (int): Extra padding around bounding box\n",
    "        show_frame_details (bool): Whether to show frame-by-frame details\n",
    "        \n",
    "    Returns:\n",
    "        bool: Success status\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open input video\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"âŒ Cannot open video: {input_video_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        print(f\"ğŸ¬ Input video: {total_frames} frames at {fps} FPS ({width}x{height})\")\n",
    "        print(f\"ğŸ“‹ Sequence data: {len(sequence_data)} frames\")\n",
    "        \n",
    "        # Create sorted list of bounding boxes by frame number\n",
    "        valid_bboxes = []\n",
    "        for _, row in sequence_data.iterrows():\n",
    "            frame_num = row['frame_num']\n",
    "            bbox = row['bbox_parsed']\n",
    "            if bbox is not None:\n",
    "                valid_bboxes.append({\n",
    "                    'frame_num': frame_num,\n",
    "                    'bbox': bbox\n",
    "                })\n",
    "        \n",
    "        if not valid_bboxes:\n",
    "            print(\"âŒ No valid bounding boxes found!\")\n",
    "            return False\n",
    "        \n",
    "        # Sort by frame number\n",
    "        valid_bboxes = sorted(valid_bboxes, key=lambda x: x['frame_num'])\n",
    "        \n",
    "        print(f\"ğŸ“¦ Found {len(valid_bboxes)} valid bounding boxes\")\n",
    "        \n",
    "        # Get GAVD frame range\n",
    "        min_gavd_frame = valid_bboxes[0]['frame_num']\n",
    "        max_gavd_frame = valid_bboxes[-1]['frame_num']\n",
    "        gavd_frame_range = max_gavd_frame - min_gavd_frame + 1\n",
    "        \n",
    "        print(f\"ğŸ¯ GAVD frame range: {min_gavd_frame} to {max_gavd_frame} ({gavd_frame_range} frames)\")\n",
    "        print(f\"ğŸ¯ Video frame range: 0 to {total_frames-1} ({total_frames} frames)\")\n",
    "        print(\"âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\")\n",
    "        \n",
    "        # Calculate maximum dimensions for consistent output size\n",
    "        all_bboxes = [item['bbox'] for item in valid_bboxes]\n",
    "        max_width = max(bbox['width'] for bbox in all_bboxes) + 2 * padding\n",
    "        max_height = max(bbox['height'] for bbox in all_bboxes) + 2 * padding\n",
    "        \n",
    "        # Ensure dimensions don't exceed original video\n",
    "        output_width = min(int(max_width), width)\n",
    "        output_height = min(int(max_height), height)\n",
    "        \n",
    "        print(f\"ğŸ“ Output video size: {output_width}x{output_height} (max bbox + padding)\")\n",
    "        \n",
    "        # Setup output video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (output_width, output_height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"âŒ Cannot create output video: {output_video_path}\")\n",
    "            cap.release()\n",
    "            return False\n",
    "        \n",
    "        frames_written = 0\n",
    "        \n",
    "        if show_frame_details:\n",
    "            print(f\"\\nğŸ“‹ FRAME-BY-FRAME DETAILS:\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        # Process each video frame with corresponding bbox\n",
    "        for video_frame_idx in range(total_frames):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Map video frame index to GAVD data\n",
    "            # Since GAVD frames might not start from 0, we need to interpolate\n",
    "            if len(valid_bboxes) == total_frames:\n",
    "                # Direct 1:1 mapping\n",
    "                bbox_data = valid_bboxes[video_frame_idx]\n",
    "            else:\n",
    "                # Interpolate based on progress through video\n",
    "                progress = video_frame_idx / max(1, total_frames - 1)\n",
    "                bbox_idx = min(int(progress * (len(valid_bboxes) - 1)), len(valid_bboxes) - 1)\n",
    "                bbox_data = valid_bboxes[bbox_idx]\n",
    "            \n",
    "            bbox = bbox_data['bbox']\n",
    "            gavd_frame_num = bbox_data['frame_num']\n",
    "            \n",
    "            # Calculate crop region for this specific frame's bbox\n",
    "            crop_top = max(0, int(bbox['top']) - padding)\n",
    "            crop_left = max(0, int(bbox['left']) - padding)\n",
    "            crop_bottom = min(int(bbox['top'] + bbox['height']) + padding, height)\n",
    "            crop_right = min(int(bbox['left'] + bbox['width']) + padding, width)\n",
    "            \n",
    "            actual_crop_width = crop_right - crop_left\n",
    "            actual_crop_height = crop_bottom - crop_top\n",
    "            \n",
    "            # Show frame details if requested\n",
    "            if show_frame_details and video_frame_idx < 10:  # Show first 10 frames\n",
    "                print(f\"Frame {video_frame_idx:3d}: GAVD={gavd_frame_num}\")\n",
    "                print(f\"  ğŸ“¦ BBox: top={bbox['top']:.1f}, left={bbox['left']:.1f}, \"\n",
    "                      f\"width={bbox['width']:.1f}, height={bbox['height']:.1f}\")\n",
    "                print(f\"  âœ‚ï¸ Crop: ({crop_left},{crop_top}) to ({crop_right},{crop_bottom}) \"\n",
    "                      f\"= {actual_crop_width}x{actual_crop_height}\")\n",
    "            \n",
    "            # Crop the frame using this frame's specific bbox\n",
    "            cropped_frame = frame[crop_top:crop_bottom, crop_left:crop_right]\n",
    "            \n",
    "            # Create output frame with consistent dimensions (centered)\n",
    "            output_frame = np.zeros((output_height, output_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            # Center the cropped frame in the output frame\n",
    "            start_y = max(0, (output_height - actual_crop_height) // 2)\n",
    "            start_x = max(0, (output_width - actual_crop_width) // 2)\n",
    "            end_y = min(output_height, start_y + actual_crop_height)\n",
    "            end_x = min(output_width, start_x + actual_crop_width)\n",
    "            \n",
    "            # Ensure we don't exceed boundaries\n",
    "            crop_h = min(actual_crop_height, end_y - start_y)\n",
    "            crop_w = min(actual_crop_width, end_x - start_x)\n",
    "            \n",
    "            output_frame[start_y:start_y+crop_h, start_x:start_x+crop_w] = cropped_frame[:crop_h, :crop_w]\n",
    "            \n",
    "            out.write(output_frame)\n",
    "            frames_written += 1\n",
    "        \n",
    "        if show_frame_details and total_frames > 10:\n",
    "            print(f\"  ... (showing first 10 frames, total: {total_frames})\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"âœ… Per-frame cropped video saved: {frames_written} frames written\")\n",
    "        \n",
    "        # Verify output file\n",
    "        if frames_written == 0:\n",
    "            print(\"âš ï¸ Warning: No frames were written to output file!\")\n",
    "            return False\n",
    "        \n",
    "        if frames_written != total_frames:\n",
    "            print(f\"âš ï¸ Warning: Expected {total_frames} frames, but wrote {frames_written}\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error cropping video: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"ğŸ”§ Per-frame dynamic cropping function defined successfully!\")\n",
    "print(\"âœ‚ï¸ Uses exact per-frame bbox data from GAVD dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Batch video cropping function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def batch_crop_videos_only(video_dir, cropped_output_dir, gavd_df, max_videos=None, \n",
    "                          skip_existing=True, show_progress=True):\n",
    "    \"\"\"\n",
    "    Batch crop all videos using bounding box data without HSMR processing.\n",
    "    \n",
    "    Args:\n",
    "        video_dir (str): Directory containing input videos\n",
    "        cropped_output_dir (str): Directory to save cropped videos\n",
    "        gavd_df (pd.DataFrame): GAVD dataset with bounding box information\n",
    "        max_videos (int, optional): Maximum number of videos to process (for testing)\n",
    "        skip_existing (bool): Whether to skip already cropped videos\n",
    "        show_progress (bool): Whether to show progress bar and detailed info\n",
    "    \n",
    "    Returns:\n",
    "        dict: Cropping statistics and results\n",
    "    \"\"\"\n",
    "    if gavd_df is None:\n",
    "        print(\"âŒ GAVD dataset not loaded. Cannot perform bounding box cropping.\")\n",
    "        return None\n",
    "    \n",
    "    # Get all video files\n",
    "    video_files = list(Path(video_dir).glob('*.mp4'))\n",
    "    \n",
    "    if max_videos:\n",
    "        video_files = video_files[:max_videos]\n",
    "    \n",
    "    print(f\"âœ‚ï¸ Starting batch video cropping\")\n",
    "    print(f\"ğŸ“ Input directory: {video_dir}\")\n",
    "    print(f\"ğŸ“ Cropped output directory: {cropped_output_dir}\")\n",
    "    print(f\"ğŸ“¼ Total videos to process: {len(video_files)}\")\n",
    "    print(f\"â­ï¸ Skip existing: {skip_existing}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(cropped_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process videos with optional progress bar\n",
    "    iterator = tqdm(video_files, desc=\"Cropping videos\") if show_progress else video_files\n",
    "    \n",
    "    for i, video_path in enumerate(iterator, 1):\n",
    "        try:\n",
    "            sequence_id = video_path.stem\n",
    "            cropped_video_path = Path(cropped_output_dir) / f\"{sequence_id}_cropped.mp4\"\n",
    "            \n",
    "            # Skip if already exists and skip_existing is True\n",
    "            if skip_existing and cropped_video_path.exists():\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    print(f\"â­ï¸ [{i:4d}/{len(video_files):4d}] Skipping {video_path.name} - already cropped\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': True,\n",
    "                    'output': cropped_video_path,\n",
    "                    'skipped': True,\n",
    "                    'error': None,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Get sequence bounding box data\n",
    "            sequence_data = get_sequence_bbox_data(sequence_id, gavd_df)\n",
    "            \n",
    "            if sequence_data is None:\n",
    "                error_msg = f\"No bounding box data found for sequence: {sequence_id}\"\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    print(f\"âš ï¸ [{i:4d}/{len(video_files):4d}] {video_path.name} - {error_msg}\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': False,\n",
    "                    'output': None,\n",
    "                    'skipped': False,\n",
    "                    'error': error_msg,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Perform per-frame cropping using GAVD bbox data\n",
    "            success = crop_video_with_bbox_per_frame(\n",
    "                str(video_path),\n",
    "                str(cropped_video_path),\n",
    "                sequence_data,\n",
    "                padding=20,\n",
    "                show_frame_details=False\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    output_size = cropped_video_path.stat().st_size / (1024*1024)\n",
    "                    print(f\"âœ… [{i:4d}/{len(video_files):4d}] {video_path.name} -> {output_size:.2f} MB\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': True,\n",
    "                    'output': cropped_video_path,\n",
    "                    'skipped': False,\n",
    "                    'error': None,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "            else:\n",
    "                error_msg = \"Cropping failed - see detailed output above\"\n",
    "                if show_progress and not isinstance(iterator, tqdm):\n",
    "                    print(f\"âŒ [{i:4d}/{len(video_files):4d}] {video_path.name} - {error_msg}\")\n",
    "                \n",
    "                results.append({\n",
    "                    'video': video_path.name,\n",
    "                    'success': False,\n",
    "                    'output': None,\n",
    "                    'skipped': False,\n",
    "                    'error': error_msg,\n",
    "                    'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "                })\n",
    "            \n",
    "            # Garbage collection every 50 videos\n",
    "            if i % 50 == 0:\n",
    "                gc.collect()\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Exception during cropping: {str(e)}\"\n",
    "            if show_progress and not isinstance(iterator, tqdm):\n",
    "                print(f\"ğŸ’¥ [{i:4d}/{len(video_files):4d}] {video_path.name} - {error_msg}\")\n",
    "            \n",
    "            results.append({\n",
    "                'video': video_path.name,\n",
    "                'success': False,\n",
    "                'output': None,\n",
    "                'skipped': False,\n",
    "                'error': error_msg,\n",
    "                'size_mb': video_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Calculate statistics\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = sum(1 for r in results if not r['success'])\n",
    "    skipped = sum(1 for r in results if r.get('skipped', False))\n",
    "    newly_cropped = successful - skipped\n",
    "    total_size_mb = sum(r['size_mb'] for r in results)\n",
    "    avg_time_per_video = total_time / len(results) if results else 0\n",
    "    \n",
    "    # Final garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    stats = {\n",
    "        'total_videos': len(results),\n",
    "        'successful': successful,\n",
    "        'failed': failed,\n",
    "        'skipped': skipped,\n",
    "        'newly_cropped': newly_cropped,\n",
    "        'total_time_seconds': total_time,\n",
    "        'avg_time_per_video': avg_time_per_video,\n",
    "        'total_size_mb': total_size_mb,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"ğŸ”§ Batch video cropping function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Testing CORRECTED per-frame cropping...\n",
      "ğŸ§ª Testing PER-FRAME cropping for sequence: cljanb45y00083n6lmh1qhydd\n",
      "======================================================================\n",
      "ğŸ“‹ Sequence Information:\n",
      "  ğŸ“¼ Sequence ID: cljanb45y00083n6lmh1qhydd\n",
      "  ğŸ“Š GAVD frames: 215\n",
      "  ğŸ¯ GAVD frame range: 2532 - 2746\n",
      "\n",
      "ğŸ“¦ Bounding Box Variation (showing per-frame changes):\n",
      "       first: top= 129.0, left= 805.0, width=247.0, height=485.0\n",
      "    frame 53: top= 127.3, left= 768.2, width=247.0, height=485.0\n",
      "   frame 107: top= 112.6, left= 659.3, width=278.4, height=501.1\n",
      "   frame 161: top= 121.8, left= 535.5, width=287.9, height=493.3\n",
      "        last: top= 131.0, left= 475.0, width=247.0, height=485.0\n",
      "\n",
      "âœ‚ï¸ Testing Per-Frame Video Cropping:\n",
      "  ğŸ“¥ Input: GAVD-sequences\\cljanb45y00083n6lmh1qhydd.mp4 (0.46 MB)\n",
      "ğŸ¬ Input video: 214 frames at 30 FPS (1280x720)\n",
      "ğŸ“‹ Sequence data: 215 frames\n",
      "ğŸ“¦ Found 215 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2532 to 2746 (215 frames)\n",
      "ğŸ¯ Video frame range: 0 to 213 (214 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 331x544 (max bbox + padding)\n",
      "\n",
      "ğŸ“‹ FRAME-BY-FRAME DETAILS:\n",
      "================================================================================\n",
      "Frame   0: GAVD=2532\n",
      "  ğŸ“¦ BBox: top=129.0, left=805.0, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (785,109) to (1072,634) = 287x525\n",
      "Frame   1: GAVD=2533\n",
      "  ğŸ“¦ BBox: top=129.0, left=804.3, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (784,108) to (1071,633) = 287x525\n",
      "Frame   2: GAVD=2534\n",
      "  ğŸ“¦ BBox: top=128.9, left=803.6, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (783,108) to (1070,633) = 287x525\n",
      "Frame   3: GAVD=2535\n",
      "  ğŸ“¦ BBox: top=128.9, left=802.9, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (782,108) to (1069,633) = 287x525\n",
      "Frame   4: GAVD=2536\n",
      "  ğŸ“¦ BBox: top=128.9, left=802.2, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (782,108) to (1069,633) = 287x525\n",
      "Frame   5: GAVD=2537\n",
      "  ğŸ“¦ BBox: top=128.8, left=801.5, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (781,108) to (1068,633) = 287x525\n",
      "Frame   6: GAVD=2538\n",
      "  ğŸ“¦ BBox: top=128.8, left=800.8, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (780,108) to (1067,633) = 287x525\n",
      "Frame   7: GAVD=2539\n",
      "  ğŸ“¦ BBox: top=128.8, left=800.1, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (780,108) to (1067,633) = 287x525\n",
      "Frame   8: GAVD=2540\n",
      "  ğŸ“¦ BBox: top=128.7, left=799.5, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (779,108) to (1066,633) = 287x525\n",
      "Frame   9: GAVD=2541\n",
      "  ğŸ“¦ BBox: top=128.7, left=798.8, width=247.0, height=485.0\n",
      "  âœ‚ï¸ Crop: (778,108) to (1065,633) = 287x525\n",
      "  ... (showing first 10 frames, total: 214)\n",
      "================================================================================\n",
      "âœ… Per-frame cropped video saved: 214 frames written\n",
      "  ğŸ“¤ Output: GAVD-cropped-sequences\\cljanb45y00083n6lmh1qhydd_per_frame_test.mp4 (0.70 MB)\n",
      "  ğŸ“Š Size change: 1.52x original\n",
      "  âœ… Per-frame cropping test SUCCESSFUL!\n",
      "  ğŸ“Š Output video: 214 frames, 330x544\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the corrected per-frame cropping function\n",
    "def test_per_frame_cropping(sequence_id=\"cljanb45y00083n6lmh1qhydd\"):\n",
    "    \"\"\"Test the corrected per-frame bounding box cropping functionality.\"\"\"\n",
    "    \n",
    "    if gavd_dataset is None:\n",
    "        print(\"âŒ GAVD dataset not loaded. Cannot test per-frame cropping.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ§ª Testing PER-FRAME cropping for sequence: {sequence_id}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get sequence data\n",
    "    sequence_data = get_sequence_bbox_data(sequence_id, gavd_dataset)\n",
    "    \n",
    "    if sequence_data is None:\n",
    "        print(f\"âŒ No data found for sequence: {sequence_id}\")\n",
    "        return\n",
    "    \n",
    "    # Check video file\n",
    "    input_video = Path(GAVD_SEQUENCES_DIR) / f\"{sequence_id}.mp4\"\n",
    "    if not input_video.exists():\n",
    "        print(f\"âŒ Input video not found: {input_video}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“‹ Sequence Information:\")\n",
    "    print(f\"  ğŸ“¼ Sequence ID: {sequence_id}\")\n",
    "    print(f\"  ğŸ“Š GAVD frames: {len(sequence_data)}\")\n",
    "    print(f\"  ğŸ¯ GAVD frame range: {sequence_data['frame_num'].min()} - {sequence_data['frame_num'].max()}\")\n",
    "    \n",
    "    # Show bbox variation to demonstrate per-frame differences\n",
    "    valid_bboxes = [bbox for bbox in sequence_data['bbox_parsed'] if bbox is not None]\n",
    "    if len(valid_bboxes) >= 5:\n",
    "        print(f\"\\nğŸ“¦ Bounding Box Variation (showing per-frame changes):\")\n",
    "        for i in [0, len(valid_bboxes)//4, len(valid_bboxes)//2, 3*len(valid_bboxes)//4, -1]:\n",
    "            bbox = valid_bboxes[i]\n",
    "            frame_idx = \"first\" if i == 0 else \"last\" if i == -1 else f\"frame {i}\"\n",
    "            print(f\"  {frame_idx:>10}: top={bbox['top']:6.1f}, left={bbox['left']:6.1f}, \"\n",
    "                  f\"width={bbox['width']:5.1f}, height={bbox['height']:5.1f}\")\n",
    "    \n",
    "    print(f\"\\nâœ‚ï¸ Testing Per-Frame Video Cropping:\")\n",
    "    print(f\"  ğŸ“¥ Input: {input_video} ({input_video.stat().st_size / (1024*1024):.2f} MB)\")\n",
    "    \n",
    "    # Clean up any existing test files\n",
    "    test_output = Path(CROPPED_VIDEOS_DIR) / f\"{sequence_id}_per_frame_test.mp4\"\n",
    "    if test_output.exists():\n",
    "        test_output.unlink()\n",
    "        print(f\"  ğŸ—‘ï¸ Removed existing test file\")\n",
    "    \n",
    "    # Perform per-frame cropping with frame details\n",
    "    success = crop_video_with_bbox_per_frame(\n",
    "        str(input_video), \n",
    "        str(test_output), \n",
    "        sequence_data,\n",
    "        padding=20,\n",
    "        show_frame_details=True  # Show detailed frame-by-frame info\n",
    "    )\n",
    "    \n",
    "    if success and test_output.exists():\n",
    "        output_size_mb = test_output.stat().st_size / (1024*1024)\n",
    "        input_size_mb = input_video.stat().st_size / (1024*1024)\n",
    "        \n",
    "        print(f\"  ğŸ“¤ Output: {test_output} ({output_size_mb:.2f} MB)\")\n",
    "        print(f\"  ğŸ“Š Size change: {output_size_mb/input_size_mb:.2f}x original\")\n",
    "        \n",
    "        if output_size_mb > 0.01:  # Check if file has reasonable size\n",
    "            print(f\"  âœ… Per-frame cropping test SUCCESSFUL!\")\n",
    "            \n",
    "            # Verify the output video can be opened\n",
    "            test_cap = cv2.VideoCapture(str(test_output))\n",
    "            if test_cap.isOpened():\n",
    "                test_frames = int(test_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                test_width = int(test_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                test_height = int(test_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                test_cap.release()\n",
    "                print(f\"  ğŸ“Š Output video: {test_frames} frames, {test_width}x{test_height}\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ Output video cannot be opened!\")\n",
    "        else:\n",
    "            print(f\"  âŒ Output file too small - cropping may have failed!\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"  âŒ Per-frame cropping test FAILED!\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Run the per-frame cropping test\n",
    "print(\"ğŸ”„ Testing CORRECTED per-frame cropping...\")\n",
    "test_per_frame_cropping()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Starting batch video cropping\n",
      "ğŸ“ Input directory: ./GAVD-sequences\n",
      "ğŸ“ Cropped output directory: ./GAVD-cropped-sequences\n",
      "ğŸ“¼ Total videos to process: 1801\n",
      "â­ï¸ Skip existing: True\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 0/1801 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Input video: 511 frames at 30 FPS (1280x720)\n",
      "ğŸ“‹ Sequence data: 512 frames\n",
      "ğŸ“¦ Found 512 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1757 to 2268 (512 frames)\n",
      "ğŸ¯ Video frame range: 0 to 510 (511 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 337x551 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 1/1801 [00:01<30:30,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 511 frames written\n",
      "ğŸ¬ Input video: 214 frames at 30 FPS (1280x720)\n",
      "ğŸ“‹ Sequence data: 215 frames\n",
      "ğŸ“¦ Found 215 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2532 to 2746 (215 frames)\n",
      "ğŸ¯ Video frame range: 0 to 213 (214 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 331x544 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 2/1801 [00:01<20:26,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 214 frames written\n",
      "ğŸ¬ Input video: 147 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 148 frames\n",
      "ğŸ“¦ Found 148 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1 to 148 (148 frames)\n",
      "ğŸ¯ Video frame range: 0 to 146 (147 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 544x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 3/1801 [00:02<20:03,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 147 frames written\n",
      "ğŸ¬ Input video: 150 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 151 frames\n",
      "ğŸ“¦ Found 151 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 205 to 355 (151 frames)\n",
      "ğŸ¯ Video frame range: 0 to 149 (150 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 598x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 4/1801 [00:02<20:16,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 150 frames written\n",
      "ğŸ¬ Input video: 431 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 432 frames\n",
      "ğŸ“¦ Found 432 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 382 to 813 (432 frames)\n",
      "ğŸ¯ Video frame range: 0 to 430 (431 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 590x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 5/1801 [00:04<32:52,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 431 frames written\n",
      "ğŸ¬ Input video: 490 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 491 frames\n",
      "ğŸ“¦ Found 491 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 852 to 1342 (491 frames)\n",
      "ğŸ¯ Video frame range: 0 to 489 (490 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 587x759 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 6/1801 [00:06<42:53,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 490 frames written\n",
      "ğŸ¬ Input video: 178 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 179 frames\n",
      "ğŸ“¦ Found 179 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1346 to 1524 (179 frames)\n",
      "ğŸ¯ Video frame range: 0 to 177 (178 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 363x718 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 7/1801 [00:07<35:40,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 178 frames written\n",
      "ğŸ¬ Input video: 177 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 178 frames\n",
      "ğŸ“¦ Found 178 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1579 to 1756 (178 frames)\n",
      "ğŸ¯ Video frame range: 0 to 176 (177 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 449x748 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 8/1801 [00:08<31:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 177 frames written\n",
      "ğŸ¬ Input video: 369 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 370 frames\n",
      "ğŸ“¦ Found 370 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1788 to 2157 (370 frames)\n",
      "ğŸ¯ Video frame range: 0 to 368 (369 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 385x731 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   0%|          | 9/1801 [00:09<34:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 369 frames written\n",
      "ğŸ¬ Input video: 508 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 509 frames\n",
      "ğŸ“¦ Found 509 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2185 to 2693 (509 frames)\n",
      "ğŸ¯ Video frame range: 0 to 507 (508 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 421x721 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|          | 13/1801 [00:11<18:21,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 508 frames written\n",
      "ğŸ¬ Input video: 112 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 113 frames\n",
      "ğŸ“¦ Found 113 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 38 to 150 (113 frames)\n",
      "ğŸ¯ Video frame range: 0 to 111 (112 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 111x259 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 112 frames written\n",
      "ğŸ¬ Input video: 118 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 119 frames\n",
      "ğŸ“¦ Found 119 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 195 to 313 (119 frames)\n",
      "ğŸ¯ Video frame range: 0 to 117 (118 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 111x268 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 118 frames written\n",
      "ğŸ¬ Input video: 113 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 114 frames\n",
      "ğŸ“¦ Found 114 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 350 to 463 (114 frames)\n",
      "ğŸ¯ Video frame range: 0 to 112 (113 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 111x267 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 113 frames written\n",
      "ğŸ¬ Input video: 103 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 104 frames\n",
      "ğŸ“¦ Found 104 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 842 to 945 (104 frames)\n",
      "ğŸ¯ Video frame range: 0 to 102 (103 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 117x272 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 103 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|          | 19/1801 [00:11<07:01,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Input video: 87 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 88 frames\n",
      "ğŸ“¦ Found 88 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1312 to 1399 (88 frames)\n",
      "ğŸ¯ Video frame range: 0 to 86 (87 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 136x266 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 87 frames written\n",
      "ğŸ¬ Input video: 97 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 98 frames\n",
      "ğŸ“¦ Found 98 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1477 to 1574 (98 frames)\n",
      "ğŸ¯ Video frame range: 0 to 96 (97 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 120x278 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 97 frames written\n",
      "ğŸ¬ Input video: 111 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 112 frames\n",
      "ğŸ“¦ Found 112 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1615 to 1726 (112 frames)\n",
      "ğŸ¯ Video frame range: 0 to 110 (111 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 117x246 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 111 frames written\n",
      "ğŸ¬ Input video: 90 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 91 frames\n",
      "ğŸ“¦ Found 91 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1785 to 1875 (91 frames)\n",
      "ğŸ¯ Video frame range: 0 to 89 (90 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 115x260 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 90 frames written\n",
      "ğŸ¬ Input video: 95 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 96 frames\n",
      "ğŸ“¦ Found 96 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1926 to 2021 (96 frames)\n",
      "ğŸ¯ Video frame range: 0 to 94 (95 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 101x239 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 95 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|          | 22/1801 [00:11<04:57,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Input video: 98 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 99 frames\n",
      "ğŸ“¦ Found 99 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2104 to 2202 (99 frames)\n",
      "ğŸ¯ Video frame range: 0 to 97 (98 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 109x260 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 98 frames written\n",
      "ğŸ¬ Input video: 104 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 105 frames\n",
      "ğŸ“¦ Found 105 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2248 to 2352 (105 frames)\n",
      "ğŸ¯ Video frame range: 0 to 103 (104 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 105x249 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 104 frames written\n",
      "ğŸ¬ Input video: 104 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 105 frames\n",
      "ğŸ“¦ Found 105 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2424 to 2528 (105 frames)\n",
      "ğŸ¯ Video frame range: 0 to 103 (104 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 110x249 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 104 frames written\n",
      "ğŸ¬ Input video: 96 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 97 frames\n",
      "ğŸ“¦ Found 97 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2571 to 2667 (97 frames)\n",
      "ğŸ¯ Video frame range: 0 to 95 (96 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 138x254 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 96 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   1%|â–         | 27/1801 [00:12<03:07,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Input video: 108 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 109 frames\n",
      "ğŸ“¦ Found 109 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2754 to 2862 (109 frames)\n",
      "ğŸ¯ Video frame range: 0 to 107 (108 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 96x258 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 108 frames written\n",
      "ğŸ¬ Input video: 99 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 100 frames\n",
      "ğŸ“¦ Found 100 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 2901 to 3000 (100 frames)\n",
      "ğŸ¯ Video frame range: 0 to 98 (99 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 142x263 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 99 frames written\n",
      "ğŸ¬ Input video: 100 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 101 frames\n",
      "ğŸ“¦ Found 101 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3083 to 3183 (101 frames)\n",
      "ğŸ¯ Video frame range: 0 to 99 (100 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 104x241 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 100 frames written\n",
      "ğŸ¬ Input video: 116 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 117 frames\n",
      "ğŸ“¦ Found 117 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3226 to 3342 (117 frames)\n",
      "ğŸ¯ Video frame range: 0 to 115 (116 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 137x300 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 116 frames written\n",
      "ğŸ¬ Input video: 111 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 112 frames\n",
      "ğŸ“¦ Found 112 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3395 to 3506 (112 frames)\n",
      "ğŸ¯ Video frame range: 0 to 110 (111 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 127x307 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 111 frames written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|â–         | 30/1801 [00:12<02:33, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Input video: 104 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 105 frames\n",
      "ğŸ“¦ Found 105 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3549 to 3653 (105 frames)\n",
      "ğŸ¯ Video frame range: 0 to 103 (104 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 140x325 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 104 frames written\n",
      "ğŸ¬ Input video: 98 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 99 frames\n",
      "ğŸ“¦ Found 99 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3709 to 3807 (99 frames)\n",
      "ğŸ¯ Video frame range: 0 to 97 (98 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 131x314 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 98 frames written\n",
      "ğŸ¬ Input video: 82 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 83 frames\n",
      "ğŸ“¦ Found 83 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3855 to 3937 (83 frames)\n",
      "ğŸ¯ Video frame range: 0 to 81 (82 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 176x330 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 82 frames written\n",
      "ğŸ¬ Input video: 90 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 91 frames\n",
      "ğŸ“¦ Found 91 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3994 to 4084 (91 frames)\n",
      "ğŸ¯ Video frame range: 0 to 89 (90 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 111x309 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 90 frames written\n",
      "ğŸ¬ Input video: 99 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 100 frames\n",
      "ğŸ“¦ Found 100 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4129 to 4228 (100 frames)\n",
      "ğŸ¯ Video frame range: 0 to 98 (99 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 142x304 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|â–         | 36/1801 [00:12<01:59, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 99 frames written\n",
      "ğŸ¬ Input video: 124 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 125 frames\n",
      "ğŸ“¦ Found 125 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4271 to 4395 (125 frames)\n",
      "ğŸ¯ Video frame range: 0 to 123 (124 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 116x291 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 124 frames written\n",
      "ğŸ¬ Input video: 128 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 129 frames\n",
      "ğŸ“¦ Found 129 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4437 to 4565 (129 frames)\n",
      "ğŸ¯ Video frame range: 0 to 127 (128 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 178x348 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 128 frames written\n",
      "ğŸ¬ Input video: 81 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 82 frames\n",
      "ğŸ“¦ Found 82 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4604 to 4685 (82 frames)\n",
      "ğŸ¯ Video frame range: 0 to 80 (81 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 124x332 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 81 frames written\n",
      "ğŸ¬ Input video: 95 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 96 frames\n",
      "ğŸ“¦ Found 96 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4725 to 4820 (96 frames)\n",
      "ğŸ¯ Video frame range: 0 to 94 (95 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 156x381 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|â–         | 39/1801 [00:12<01:47, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 95 frames written\n",
      "ğŸ¬ Input video: 69 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 70 frames\n",
      "ğŸ“¦ Found 70 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4891 to 4960 (70 frames)\n",
      "ğŸ¯ Video frame range: 0 to 68 (69 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 134x334 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 69 frames written\n",
      "ğŸ¬ Input video: 80 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 81 frames\n",
      "ğŸ“¦ Found 81 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 5002 to 5082 (81 frames)\n",
      "ğŸ¯ Video frame range: 0 to 79 (80 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 135x352 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 80 frames written\n",
      "ğŸ¬ Input video: 33 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 34 frames\n",
      "ğŸ“¦ Found 34 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 5191 to 5224 (34 frames)\n",
      "ğŸ¯ Video frame range: 0 to 32 (33 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 107x256 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 33 frames written\n",
      "ğŸ¬ Input video: 38 frames at 30 FPS (272x480)\n",
      "ğŸ“‹ Sequence data: 39 frames\n",
      "ğŸ“¦ Found 39 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 5269 to 5307 (39 frames)\n",
      "ğŸ¯ Video frame range: 0 to 37 (38 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 125x296 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 38 frames written\n",
      "ğŸ¬ Input video: 305 frames at 29 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 306 frames\n",
      "ğŸ“¦ Found 306 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1 to 306 (306 frames)\n",
      "ğŸ¯ Video frame range: 0 to 304 (305 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 492x701 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|â–         | 42/1801 [00:14<05:07,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 305 frames written\n",
      "ğŸ¬ Input video: 259 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 260 frames\n",
      "ğŸ“¦ Found 260 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1 to 260 (260 frames)\n",
      "ğŸ¯ Video frame range: 0 to 258 (259 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 448x753 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   2%|â–         | 44/1801 [00:15<07:18,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 259 frames written\n",
      "ğŸ¬ Input video: 300 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 301 frames\n",
      "ğŸ“¦ Found 301 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 390 to 690 (301 frames)\n",
      "ğŸ¯ Video frame range: 0 to 299 (300 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 408x732 (max bbox + padding)\n",
      "âœ… Per-frame cropped video saved: 300 frames written\n",
      "ğŸ¬ Input video: 1037 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 1038 frames\n",
      "ğŸ“¦ Found 1038 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 761 to 1798 (1038 frames)\n",
      "ğŸ¯ Video frame range: 0 to 1036 (1037 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 489x756 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 46/1801 [00:20<25:16,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 1037 frames written\n",
      "ğŸ¬ Input video: 227 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 228 frames\n",
      "ğŸ“¦ Found 228 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 3865 to 4092 (228 frames)\n",
      "ğŸ¯ Video frame range: 0 to 226 (227 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 312x733 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 48/1801 [00:21<23:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 227 frames written\n",
      "ğŸ¬ Input video: 228 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 229 frames\n",
      "ğŸ“¦ Found 229 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4204 to 4432 (229 frames)\n",
      "ğŸ¯ Video frame range: 0 to 227 (228 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 266x672 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 49/1801 [00:22<24:51,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 228 frames written\n",
      "ğŸ¬ Input video: 941 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 942 frames\n",
      "ğŸ“¦ Found 942 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 4635 to 5576 (942 frames)\n",
      "ğŸ¯ Video frame range: 0 to 940 (941 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 315x738 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 50/1801 [00:28<48:42,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 941 frames written\n",
      "ğŸ¬ Input video: 888 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 889 frames\n",
      "ğŸ“¦ Found 889 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 6010 to 6898 (889 frames)\n",
      "ğŸ¯ Video frame range: 0 to 887 (888 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 272x674 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 51/1801 [00:32<1:06:14,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 888 frames written\n",
      "ğŸ¬ Input video: 328 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 329 frames\n",
      "ğŸ“¦ Found 329 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1 to 329 (329 frames)\n",
      "ğŸ¯ Video frame range: 0 to 327 (328 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 335x758 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 52/1801 [00:34<1:03:29,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 328 frames written\n",
      "ğŸ¬ Input video: 343 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 344 frames\n",
      "ğŸ“¦ Found 344 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 429 to 772 (344 frames)\n",
      "ğŸ¯ Video frame range: 0 to 342 (343 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 363x743 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 53/1801 [00:36<1:02:38,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 343 frames written\n",
      "ğŸ¬ Input video: 1108 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 1109 frames\n",
      "ğŸ“¦ Found 1109 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 792 to 1900 (1109 frames)\n",
      "ğŸ¯ Video frame range: 0 to 1107 (1108 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 354x760 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 54/1801 [00:42<1:29:46,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Per-frame cropped video saved: 1108 frames written\n",
      "ğŸ¬ Input video: 1225 frames at 60 FPS (1920x1080)\n",
      "ğŸ“‹ Sequence data: 1226 frames\n",
      "ğŸ“¦ Found 1226 valid bounding boxes\n",
      "ğŸ¯ GAVD frame range: 1937 to 3162 (1226 frames)\n",
      "ğŸ¯ Video frame range: 0 to 1224 (1225 frames)\n",
      "âœ‚ï¸ Using PER-FRAME dynamic cropping (exact bbox per frame)\n",
      "ğŸ“ Output video size: 355x728 (max bbox + padding)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cropping videos:   3%|â–         | 54/1801 [00:43<23:29,  1.24it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run batch video cropping for all sequences\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This will create cropped videos for all sequences without running HSMR\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# For full processing: process all videos\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m crop_stats \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_crop_videos_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGAVD_SEQUENCES_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCROPPED_VIDEOS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgavd_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmax_videos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_existing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m crop_stats:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 82\u001b[0m, in \u001b[0;36mbatch_crop_videos_only\u001b[1;34m(video_dir, cropped_output_dir, gavd_df, max_videos, skip_existing, show_progress)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Perform per-frame cropping using GAVD bbox data\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[43mcrop_video_with_bbox_per_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcropped_video_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_frame_details\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m show_progress \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iterator, tqdm):\n",
      "Cell \u001b[1;32mIn[22], line 92\u001b[0m, in \u001b[0;36mcrop_video_with_bbox_per_frame\u001b[1;34m(input_video_path, output_video_path, sequence_data, padding, show_frame_details)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Process each video frame with corresponding bbox\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_frame_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_frames):\n\u001b[1;32m---> 92\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run batch video cropping for all sequences\n",
    "# This will create cropped videos for all sequences without running HSMR\n",
    "\n",
    "# For testing: process only a few videos\n",
    "# crop_stats = batch_crop_videos_only(GAVD_SEQUENCES_DIR, CROPPED_VIDEOS_DIR, gavd_dataset, \n",
    "#                                   max_videos=10, skip_existing=True, show_progress=True)\n",
    "\n",
    "# For full processing: process all videos\n",
    "crop_stats = batch_crop_videos_only(GAVD_SEQUENCES_DIR, CROPPED_VIDEOS_DIR, gavd_dataset, \n",
    "                                  max_videos=None, skip_existing=True, show_progress=True)\n",
    "\n",
    "if crop_stats:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ‚ï¸ BATCH VIDEO CROPPING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ğŸ“¼ Total videos processed: {crop_stats['total_videos']}\")\n",
    "    print(f\"âœ… Successfully cropped: {crop_stats['successful']}\")\n",
    "    print(f\"âŒ Failed to crop: {crop_stats['failed']}\")\n",
    "    print(f\"â­ï¸ Skipped (already existed): {crop_stats['skipped']}\")\n",
    "    print(f\"ğŸ†• Newly cropped: {crop_stats['newly_cropped']}\")\n",
    "    print(f\"â±ï¸ Total time: {crop_stats['total_time_seconds']:.2f} seconds ({crop_stats['total_time_seconds']/60:.1f} minutes)\")\n",
    "    print(f\"âš¡ Average time per video: {crop_stats['avg_time_per_video']:.2f} seconds\")\n",
    "    print(f\"ğŸ’¾ Total input size: {crop_stats['total_size_mb']:.1f} MB\")\n",
    "    \n",
    "    # Show failed videos if any\n",
    "    if crop_stats['failed'] > 0:\n",
    "        print(f\"\\nâŒ Failed cropping videos:\")\n",
    "        failed_videos = [r for r in crop_stats['results'] if not r['success']]\n",
    "        for failed in failed_videos[:10]:  # Show first 10 failures\n",
    "            print(f\"  - {failed['video']}: {failed['error']}\")\n",
    "        if len(failed_videos) > 10:\n",
    "            print(f\"  ... and {len(failed_videos) - 10} more failures\")\n",
    "    \n",
    "    # Show cropped videos directory info\n",
    "    print(f\"\\nğŸ“ Cropped videos saved to: {CROPPED_VIDEOS_DIR}\")\n",
    "    cropped_videos = list(Path(CROPPED_VIDEOS_DIR).glob('*.mp4'))\n",
    "    if cropped_videos:\n",
    "        total_cropped_size = sum(v.stat().st_size for v in cropped_videos) / (1024*1024)\n",
    "        print(f\"âœ‚ï¸ Total cropped videos: {len(cropped_videos)} ({total_cropped_size:.1f} MB total)\")\n",
    "        \n",
    "        # Show some statistics about the cropped videos\n",
    "        sample_videos = cropped_videos[:5]\n",
    "        print(f\"\\nğŸ“Š Sample cropped videos:\")\n",
    "        for video in sample_videos:\n",
    "            size_mb = video.stat().st_size / (1024*1024)\n",
    "            print(f\"  ğŸ“„ {video.name} ({size_mb:.2f} MB)\")\n",
    "        if len(cropped_videos) > 5:\n",
    "            print(f\"  ... and {len(cropped_videos) - 5} more\")\n",
    "    else:\n",
    "        print(\"âœ‚ï¸ No cropped videos found\")\n",
    "        \n",
    "    print(f\"\\nğŸ¯ Success rate: {crop_stats['successful']/crop_stats['total_videos']*100:.1f}%\")\n",
    "else:\n",
    "    print(\"âŒ Cropping operation failed to initialize\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
